{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyroxy Demo: Surrogate Models for Expensive Functions\n",
    "\n",
    "The `pyroxy` module provides a decorator that replaces expensive function calls with fast surrogate model predictions. The surrogate model is a machine learning model (typically Gaussian Process Regression) that learns from previous function evaluations.\n",
    "\n",
    "## Key Concept\n",
    "\n",
    "When you call a function decorated with `@Surrogate`:\n",
    "1. **First calls**: The actual function runs to gather training data\n",
    "2. **Subsequent calls**: The surrogate predicts the result\n",
    "3. **Uncertainty check**: If prediction uncertainty is high, run the real function and retrain\n",
    "4. **Otherwise**: Return the fast surrogate prediction\n",
    "\n",
    "This is particularly useful for:\n",
    "- Expensive numerical simulations\n",
    "- Optimization problems with costly objective functions\n",
    "- Parameter sweeps that call the same function many times\n",
    "- Any function where evaluation time >> prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import time\n",
    "\n",
    "from pycse.pyroxy import Surrogate, MaxCallsExceededException\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Usage - Expensive Sine Function\n",
    "\n",
    "Let's start with a simple example where we artificially make `sin(x)` expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "gpr_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, random_state=42)\n",
    "\n",
    "\n",
    "# Define an expensive function\n",
    "@Surrogate(model=gpr_model, tol=0.1, verbose=True)\n",
    "def expensive_sin(X):\n",
    "    \"\"\"An artificially expensive sin function.\"\"\"\n",
    "    time.sleep(0.01)  # Simulate expensive computation\n",
    "    return np.sin(X).flatten()\n",
    "\n",
    "\n",
    "# Build training data using add() - this is the recommended approach\n",
    "print(\"Building training data:\")\n",
    "X_train = np.array([[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]])\n",
    "start = time.time()\n",
    "expensive_sin.add(X_train)  # Add all training data at once\n",
    "train_time = time.time() - start\n",
    "print(f\"Training time: {train_time:.2f}s for {len(X_train)} points\")\n",
    "\n",
    "# Now test - subsequent calls should use surrogate\n",
    "print(\"\\nTesting surrogate predictions:\")\n",
    "X_test = np.array([[1.5], [2.5], [3.5], [4.5]])\n",
    "start = time.time()\n",
    "for x in X_test:\n",
    "    result = expensive_sin(x)\n",
    "    print(f\"  X={x[0]:.1f}, result={result[0]:.4f}\")\n",
    "test_time = time.time() - start\n",
    "print(f\"\\nTest time: {test_time:.2f}s for {len(X_test)} predictions\")\n",
    "print(f\"Speedup: {(train_time / len(X_train)) / (test_time / len(X_test)):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Surrogate\n",
    "\n",
    "Let's look at the surrogate's statistics and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics\n",
    "print(expensive_sin)\n",
    "\n",
    "# Visualize the surrogate fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "expensive_sin.plot()\n",
    "plt.title(\"Surrogate Model Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: More Complex Function - Quadratic 2D Function\n",
    "\n",
    "Let's use a 2D function to demonstrate multi-dimensional surrogates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model for 2D input\n",
    "kernel_2d = C(1.0, (1e-3, 1e3)) * RBF([1.0, 1.0], (1e-2, 1e2))\n",
    "gpr_2d = GaussianProcessRegressor(kernel=kernel_2d, n_restarts_optimizer=3, random_state=42)\n",
    "\n",
    "\n",
    "@Surrogate(model=gpr_2d, tol=1.0, verbose=False)\n",
    "def expensive_quadratic(X):\n",
    "    \"\"\"A 2D quadratic function.\"\"\"\n",
    "    time.sleep(0.01)  # Simulate expensive computation\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    return x**2 + y**2\n",
    "\n",
    "\n",
    "# Train with some initial points\n",
    "print(\"Training the surrogate...\")\n",
    "X_train_2d = np.random.uniform(-3, 3, size=(20, 2))\n",
    "start = time.time()\n",
    "expensive_quadratic.add(X_train_2d)\n",
    "train_time = time.time() - start\n",
    "print(f\"Training time: {train_time:.2f}s\")\n",
    "\n",
    "# Test the surrogate\n",
    "print(\"\\nTesting the surrogate...\")\n",
    "X_test_2d = np.random.uniform(-3, 3, size=(30, 2))\n",
    "start = time.time()\n",
    "results = []\n",
    "for i in range(len(X_test_2d)):\n",
    "    result = expensive_quadratic(X_test_2d[i : i + 1])\n",
    "    results.append(result[0])\n",
    "test_time = time.time() - start\n",
    "print(f\"Test time: {test_time:.2f}s\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nFunction calls: {expensive_quadratic.func_calls}\")\n",
    "print(f\"Surrogate uses: {expensive_quadratic.surrogate}\")\n",
    "if expensive_quadratic.surrogate > 0:\n",
    "    print(f\"Speedup: {(train_time / len(X_train_2d)) / (test_time / len(X_test_2d)):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Using `test()` Method to Verify Accuracy\n",
    "\n",
    "Use the `test()` method to verify surrogate accuracy at specific points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0) * RBF(1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "\n",
    "\n",
    "@Surrogate(model=gpr, tol=0.1, verbose=False)\n",
    "def cubic(X):\n",
    "    \"\"\"A cubic function.\"\"\"\n",
    "    return (X**3 - 2 * X**2 + X).flatten()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "X_train = np.linspace(-2, 3, 15).reshape(-1, 1)\n",
    "cubic.add(X_train)\n",
    "\n",
    "# Test at various points\n",
    "test_points = np.array([[0.5], [1.5], [2.5]])\n",
    "print(\"Testing surrogate accuracy:\")\n",
    "for x in test_points:\n",
    "    passed = cubic.test(x)\n",
    "    print(f\"  X={x[0]:.1f}, Test {'PASSED' if passed else 'FAILED'}\")\n",
    "\n",
    "print(f\"\\nTotal function calls (including tests): {cubic.func_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Maximum Function Calls Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0) * RBF(1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "\n",
    "\n",
    "# Limit to only 3 function calls\n",
    "@Surrogate(model=gpr, tol=0.1, max_calls=3, verbose=True)\n",
    "def limited_function(X):\n",
    "    \"\"\"Function with limited calls.\"\"\"\n",
    "    return np.exp(-(X**2)).flatten()\n",
    "\n",
    "\n",
    "# Use up the allowed calls\n",
    "X_points = np.array([[0.0], [1.0], [2.0]])\n",
    "limited_function.add(X_points)\n",
    "print(f\"Function calls used: {limited_function.func_calls}/{limited_function.max_calls}\")\n",
    "\n",
    "# Try to exceed the limit by adding more data\n",
    "try:\n",
    "    limited_function.add(np.array([[3.0]]))\n",
    "except MaxCallsExceededException as e:\n",
    "    print(f\"\\nCaught expected exception: {e}\")\n",
    "\n",
    "# But surrogate predictions still work\n",
    "print(\"\\nSurrogate predictions (no function call needed):\")\n",
    "X_interp = np.array([[0.5], [1.5]])\n",
    "for x in X_interp:\n",
    "    result = limited_function(x)\n",
    "    print(f\"  X={x[0]:.2f}, result={result[0]:.4f}\")\n",
    "print(f\"\\nSurrogate was used {limited_function.surrogate} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Using in Optimization\n",
    "\n",
    "A practical use case: speeding up optimization of an expensive 1D function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Create surrogate for a complicated 1D function\n",
    "kernel = C(1.0) * RBF(1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "\n",
    "call_count = {\"actual\": 0}  # Track actual function calls\n",
    "\n",
    "\n",
    "def complicated_function_actual(X):\n",
    "    \"\"\"A complicated 1D function.\"\"\"\n",
    "    call_count[\"actual\"] += 1\n",
    "    time.sleep(0.001)  # Simulate expensive computation\n",
    "    x = X.flatten()[0]\n",
    "    return np.sin(x) * np.cos(x / 2) + 0.1 * x**2\n",
    "\n",
    "\n",
    "# Build initial surrogate with some points\n",
    "print(\"Building initial surrogate...\")\n",
    "X_init = np.linspace(-10, 10, 20).reshape(-1, 1)\n",
    "y_init = np.array([complicated_function_actual(X.reshape(1, -1)) for X in X_init])\n",
    "print(f\"Initial training: {call_count['actual']} function calls\")\n",
    "\n",
    "\n",
    "# Now create surrogate\n",
    "@Surrogate(model=gpr, tol=0.5, verbose=False)\n",
    "def complicated_function(X):\n",
    "    return complicated_function_actual(X)\n",
    "\n",
    "\n",
    "# Initialize with training data\n",
    "complicated_function.xtrain = X_init\n",
    "complicated_function.ytrain = y_init\n",
    "complicated_function.model.fit(X_init, y_init)\n",
    "complicated_function.ntrain = 1\n",
    "complicated_function.func_calls = call_count[\"actual\"]\n",
    "\n",
    "# Optimize using the surrogate\n",
    "print(\"\\nOptimizing with surrogate...\")\n",
    "initial_calls = call_count[\"actual\"]\n",
    "\n",
    "\n",
    "def objective(x):\n",
    "    \"\"\"Wrapper for optimizer (takes scalar).\"\"\"\n",
    "    X = np.array([[x]])\n",
    "    return complicated_function(X)[0]\n",
    "\n",
    "\n",
    "result = minimize_scalar(objective, bounds=(-10, 10), method=\"bounded\")\n",
    "\n",
    "print(\"\\nOptimization complete!\")\n",
    "print(f\"Best solution: x={result.x:.4f}\")\n",
    "print(f\"Best value: f(x)={result.fun:.4f}\")\n",
    "print(\"\\nFunction call statistics:\")\n",
    "print(f\"  Total actual calls: {call_count['actual']}\")\n",
    "print(f\"  Calls during optimization: {call_count['actual'] - initial_calls}\")\n",
    "print(f\"  Surrogate predictions: {complicated_function.surrogate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Saving and Loading Surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create a surrogate\n",
    "kernel = C(1.0) * RBF(1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "\n",
    "\n",
    "@Surrogate(model=gpr, tol=0.1)\n",
    "def my_function(X):\n",
    "    return (X**2 + 2 * X + 1).flatten()\n",
    "\n",
    "\n",
    "# Train it\n",
    "X_train = np.linspace(-5, 5, 20).reshape(-1, 1)\n",
    "my_function.add(X_train)\n",
    "\n",
    "print(\"Original surrogate:\")\n",
    "print(f\"  Function calls: {my_function.func_calls}\")\n",
    "print(f\"  Training points: {len(my_function.xtrain)}\")\n",
    "\n",
    "# Save it\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    save_path = os.path.join(tmpdir, \"my_surrogate.pkl\")\n",
    "    my_function.dump(save_path)\n",
    "    print(f\"\\nSaved to: {save_path}\")\n",
    "\n",
    "    # Load it\n",
    "    loaded_surrogate = Surrogate.load(save_path)\n",
    "    print(\"\\nLoaded surrogate:\")\n",
    "    print(f\"  Function calls: {loaded_surrogate.func_calls}\")\n",
    "    print(f\"  Training points: {len(loaded_surrogate.xtrain)}\")\n",
    "\n",
    "    # Test the loaded surrogate\n",
    "    X_test = np.array([[2.5], [-2.5]])\n",
    "    print(\"\\nTesting loaded surrogate:\")\n",
    "    for x in X_test:\n",
    "        result = loaded_surrogate(x)\n",
    "        expected = (x**2 + 2 * x + 1)[0][0]\n",
    "        print(f\"  X={x[0]:.1f}, predicted={result[0]:.2f}, expected={expected:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Visualizing Surrogate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple function\n",
    "kernel = C(1.0) * RBF(1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "\n",
    "\n",
    "@Surrogate(model=gpr, tol=0.15, verbose=False)\n",
    "def wavy_function(X):\n",
    "    \"\"\"A wavy function.\"\"\"\n",
    "    return np.sin(2 * X) + 0.5 * np.cos(5 * X)\n",
    "\n",
    "\n",
    "# Train with sparse data\n",
    "X_train = np.array([[0], [1], [2], [3], [4], [5]])\n",
    "wavy_function.add(X_train)\n",
    "\n",
    "# Test on dense grid\n",
    "X_dense = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "y_true = np.sin(2 * X_dense) + 0.5 * np.cos(5 * X_dense)\n",
    "y_pred = []\n",
    "for x in X_dense:\n",
    "    y_pred.append(wavy_function(x)[0])\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(X_dense, y_true.flatten(), \"b-\", label=\"True Function\", alpha=0.7, linewidth=2)\n",
    "plt.plot(X_dense, y_pred, \"r--\", label=\"Surrogate\", alpha=0.7, linewidth=2)\n",
    "plt.scatter(\n",
    "    X_train,\n",
    "    np.sin(2 * X_train) + 0.5 * np.cos(5 * X_train),\n",
    "    color=\"green\",\n",
    "    s=100,\n",
    "    zorder=5,\n",
    "    label=\"Training Points\",\n",
    ")\n",
    "plt.xlabel(\"X\", fontsize=12)\n",
    "plt.ylabel(\"f(X)\", fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.title(\"Function Approximation\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = np.abs(y_true.flatten() - y_pred)\n",
    "plt.plot(X_dense, errors, \"g-\", linewidth=2)\n",
    "plt.xlabel(\"X\", fontsize=12)\n",
    "plt.ylabel(\"Absolute Error\", fontsize=12)\n",
    "plt.title(f\"Prediction Error (max: {np.max(errors):.4f})\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"  Function calls: {wavy_function.func_calls}\")\n",
    "print(f\"  Surrogate predictions: {wavy_function.surrogate}\")\n",
    "print(f\"  Mean absolute error: {np.mean(errors):.4f}\")\n",
    "print(f\"  Max absolute error: {np.max(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `pyroxy` module provides efficient surrogate modeling:\n",
    "\n",
    "### Key Features:\n",
    "- **Automatic caching**: Expensive function results are cached and learned\n",
    "- **Uncertainty-aware**: Only calls the real function when predictions are uncertain\n",
    "- **Flexible models**: Works with any sklearn model that provides `predict(return_std=True)`\n",
    "- **Easy to use**: Simple decorator syntax\n",
    "- **Serialization**: Save and load trained surrogates\n",
    "- **Safety limits**: `max_calls` prevents runaway function evaluations\n",
    "\n",
    "### When to Use:\n",
    "- **Expensive simulations**: Physics simulations, finite element analysis, etc.\n",
    "- **Optimization**: When the objective function is costly to evaluate\n",
    "- **Parameter sweeps**: Exploring parameter spaces efficiently\n",
    "- **Real-time applications**: Where function evaluation time is critical\n",
    "\n",
    "### Best Practices:\n",
    "1. **Choose `tol` carefully**: Lower = more accurate but more function calls\n",
    "2. **Initial training**: Use `add()` to build a good initial training set\n",
    "3. **Model selection**: Gaussian Process works well for smooth functions\n",
    "4. **Monitor statistics**: Check `func_calls` vs `surrogate` usage\n",
    "5. **Test accuracy**: Use `test()` method to verify surrogate quality\n",
    "6. **Save trained models**: Use `dump()` to avoid retraining\n",
    "7. **Array shapes**: Always ensure X is 2D (use `X.reshape(-1, 1)` for 1D data)\n",
    "\n",
    "### Performance Tips:\n",
    "- For 100+ evaluations, surrogates can provide 10-100x speedup\n",
    "- Initial training cost is amortized over many predictions\n",
    "- Works best when function is smooth and relatively low-dimensional (< 10D)\n",
    "- Use `add()` to provide initial training data for better coverage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
