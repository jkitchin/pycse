{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAN: Kolmogorov-Arnold Networks Demo\n",
    "\n",
    "This notebook demonstrates the KAN (Kolmogorov-Arnold Networks) implementation in pycse.\n",
    "\n",
    "## What are KANs?\n",
    "\n",
    "KANs are neural networks based on the Kolmogorov-Arnold representation theorem, which states that any multivariate continuous function can be represented as a composition of continuous functions of a single variable and addition.\n",
    "\n",
    "**Key differences from MLPs:**\n",
    "- MLPs have fixed activation functions on **nodes** (neurons)\n",
    "- KANs have **learnable activation functions on edges** (connections)\n",
    "- KAN activations are parameterized using B-splines\n",
    "\n",
    "**Advantages:**\n",
    "- Can be more interpretable (each edge learns a specific transformation)\n",
    "- Often more parameter-efficient for smooth functions\n",
    "- Better at learning symbolic/mathematical relationships\n",
    "\n",
    "Reference: Liu, Z., et al. (2024). KAN: Kolmogorov-Arnold Networks. arXiv:2404.19756."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import KAN from pycse\n",
    "from pycse.sklearn.kan import KAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Usage: Fitting a Simple Function\n",
    "\n",
    "Let's start with a simple example: fitting a sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sinusoidal data with noise\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 2 * np.pi, 150)[:, None]\n",
    "y_true = np.sin(X.ravel())\n",
    "y = y_true + 0.1 * np.random.randn(150)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train KAN\n",
    "# layers=(1, 8, 1) means: 1 input, 8 hidden neurons, 1 output\n",
    "model = KAN(layers=(1, 8, 1), grid_size=8)\n",
    "model.fit(X_train, y_train, maxiter=500)\n",
    "\n",
    "# Report training results\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_train, y_train, alpha=0.5, label='Training data')\n",
    "plt.scatter(X_test, y_test, alpha=0.5, label='Test data')\n",
    "plt.plot(X, y_pred, 'r-', linewidth=2, label='KAN prediction')\n",
    "plt.plot(X, y_true, 'g--', linewidth=1, label='True function')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('KAN Fitting a Sine Wave')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print R² score\n",
    "print(f\"R² score on test set: {model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uncertainty Quantification with KAN\n",
    "\n",
    "By using an ensemble output (multiple outputs in the final layer), KAN can provide uncertainty estimates similar to DPOSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heteroscedastic data (noise increases with X)\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 1, 200)[:, None]\n",
    "noise_level = 0.02 + 0.15 * X.ravel()  # Increasing noise\n",
    "y = X.ravel() ** (1/3) + noise_level * np.random.randn(200)\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KAN with ensemble output for UQ\n",
    "# layers=(1, 10, 32) means: 1 input, 10 hidden, 32 ensemble members\n",
    "model_uq = KAN(\n",
    "    layers=(1, 10, 32),\n",
    "    grid_size=5,\n",
    "    loss_type='crps',  # CRPS loss for uncertainty training\n",
    ")\n",
    "\n",
    "# Fit with validation data for calibration\n",
    "model_uq.fit(X_train, y_train, val_X=X_val, val_y=y_val, maxiter=500)\n",
    "model_uq.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in plot method\n",
    "plt.figure(figsize=(10, 6))\n",
    "model_uq.plot(X, y, distribution=True)\n",
    "plt.title('KAN with Uncertainty Quantification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print uncertainty metrics\n",
    "model_uq.print_metrics(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing KAN with Different Grid Sizes\n",
    "\n",
    "The `grid_size` parameter controls the expressiveness of the B-spline activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a more complex function\n",
    "np.random.seed(42)\n",
    "X = np.linspace(-2, 2, 200)[:, None]\n",
    "y_true = np.sin(2 * X.ravel()) * np.exp(-0.3 * X.ravel()**2)\n",
    "y = y_true + 0.05 * np.random.randn(200)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Test different grid sizes\n",
    "grid_sizes = [3, 5, 10]\n",
    "models = []\n",
    "\n",
    "fig, axes = plt.subplots(1, len(grid_sizes), figsize=(15, 4))\n",
    "\n",
    "for ax, grid_size in zip(axes, grid_sizes):\n",
    "    model = KAN(layers=(1, 6, 1), grid_size=grid_size)\n",
    "    model.fit(X_train, y_train, maxiter=500)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    ax.scatter(X_train, y_train, alpha=0.3, s=20, label='Train')\n",
    "    ax.plot(X, y_pred, 'r-', linewidth=2, label='KAN')\n",
    "    ax.plot(X, y_true, 'g--', linewidth=1, alpha=0.7, label='True')\n",
    "    ax.set_title(f'Grid Size = {grid_size}\\nR² = {score:.4f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-dimensional Input\n",
    "\n",
    "KANs can also handle multiple input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D function: z = sin(x) * cos(y)\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "X = np.random.uniform(-np.pi, np.pi, (n_samples, 2))\n",
    "y_true = np.sin(X[:, 0]) * np.cos(X[:, 1])\n",
    "y = y_true + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train KAN\n",
    "model_2d = KAN(layers=(2, 8, 1), grid_size=5)\n",
    "model_2d.fit(X_train, y_train, maxiter=500)\n",
    "\n",
    "model_2d.report()\n",
    "print(f\"\\nR² on test set: {model_2d.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 2D function\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a grid for visualization\n",
    "x_grid = np.linspace(-np.pi, np.pi, 50)\n",
    "y_grid = np.linspace(-np.pi, np.pi, 50)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "XY_flat = np.column_stack([X_grid.ravel(), Y_grid.ravel()])\n",
    "\n",
    "# Predict on grid\n",
    "Z_pred = model_2d.predict(XY_flat).reshape(X_grid.shape)\n",
    "Z_true = (np.sin(X_grid) * np.cos(Y_grid))\n",
    "\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(X_grid, Y_grid, Z_true, cmap='viridis', alpha=0.7)\n",
    "ax1.set_title('True Function: sin(x) * cos(y)')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot_surface(X_grid, Y_grid, Z_pred, cmap='viridis', alpha=0.7)\n",
    "ax2.set_title('KAN Prediction')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison: KAN vs Standard MLP (DPOSE)\n",
    "\n",
    "Let's compare KAN with DPOSE on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycse.sklearn.dpose import DPOSE\n",
    "\n",
    "# Generate data with a moderately complex function\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 4 * np.pi, 200)[:, None]\n",
    "y_true = np.sin(X.ravel()) + 0.3 * np.sin(3 * X.ravel())\n",
    "y = y_true + 0.1 * np.random.randn(200)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KAN\n",
    "kan_model = KAN(layers=(1, 10, 1), grid_size=8)\n",
    "kan_model.fit(X_train, y_train, maxiter=500)\n",
    "\n",
    "# Train DPOSE (standard MLP)\n",
    "dpose_model = DPOSE(layers=(1, 20, 1), loss_type='mse')\n",
    "dpose_model.fit(X_train, y_train, maxiter=500)\n",
    "\n",
    "# Compare\n",
    "kan_score = kan_model.score(X_test, y_test)\n",
    "dpose_score = dpose_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"KAN R² score: {kan_score:.4f}\")\n",
    "print(f\"DPOSE R² score: {dpose_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# KAN predictions\n",
    "y_kan = kan_model.predict(X)\n",
    "axes[0].scatter(X_train, y_train, alpha=0.3, label='Train')\n",
    "axes[0].scatter(X_test, y_test, alpha=0.5, label='Test')\n",
    "axes[0].plot(X, y_kan, 'r-', linewidth=2, label='KAN')\n",
    "axes[0].plot(X, y_true, 'g--', alpha=0.5, label='True')\n",
    "axes[0].set_title(f'KAN (R² = {kan_score:.4f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# DPOSE predictions\n",
    "y_dpose = dpose_model.predict(X)\n",
    "axes[1].scatter(X_train, y_train, alpha=0.3, label='Train')\n",
    "axes[1].scatter(X_test, y_test, alpha=0.5, label='Test')\n",
    "axes[1].plot(X, y_dpose, 'r-', linewidth=2, label='DPOSE')\n",
    "axes[1].plot(X, y_true, 'g--', alpha=0.5, label='True')\n",
    "axes[1].set_title(f'DPOSE (R² = {dpose_score:.4f})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Uncertainty Propagation\n",
    "\n",
    "Like DPOSE, KAN with ensemble output supports uncertainty propagation for derived quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0.5, 3, 100)[:, None]\n",
    "y = np.log(X.ravel()) + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Train KAN with ensemble for UQ\n",
    "model = KAN(layers=(1, 8, 32), grid_size=5, loss_type='crps')\n",
    "model.fit(X, y, maxiter=500)\n",
    "\n",
    "# Get ensemble predictions\n",
    "ensemble_preds = model.predict_ensemble(X)  # shape: (n_samples, n_ensemble)\n",
    "\n",
    "# Propagate through a nonlinear transformation: z = exp(y)\n",
    "z_ensemble = np.exp(ensemble_preds)\n",
    "z_mean = z_ensemble.mean(axis=1)\n",
    "z_std = z_ensemble.std(axis=1)\n",
    "\n",
    "# Compare with true values\n",
    "z_true = np.exp(np.log(X.ravel()))  # = X\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.fill_between(X.ravel(), z_mean - 2*z_std, z_mean + 2*z_std, alpha=0.3, color='red', label='±2σ')\n",
    "plt.plot(X, z_mean, 'r-', linewidth=2, label='exp(KAN prediction)')\n",
    "plt.plot(X, z_true, 'g--', linewidth=2, label='True exp(log(x)) = x')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('exp(y)')\n",
    "plt.legend()\n",
    "plt.title('Uncertainty Propagation: z = exp(y)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The KAN (Kolmogorov-Arnold Network) implementation in pycse provides:\n",
    "\n",
    "1. **Learnable activations**: B-spline basis functions for flexible activation learning\n",
    "2. **sklearn compatibility**: Follows BaseEstimator/RegressorMixin interface\n",
    "3. **Uncertainty quantification**: Via ensemble output and calibration\n",
    "4. **Flexible architecture**: Configurable grid size, spline order, and layer sizes\n",
    "5. **Multiple optimizers**: BFGS, Adam, SGD support\n",
    "\n",
    "### When to use KAN:\n",
    "- When you expect the underlying function to be smooth\n",
    "- When interpretability matters (each edge learns a specific transformation)\n",
    "- For scientific/mathematical modeling where functions are often compositions of simpler functions\n",
    "\n",
    "### Parameters to tune:\n",
    "- `grid_size`: More intervals = more expressive but more parameters (default: 5)\n",
    "- `layers`: Network architecture (include ensemble size as last element for UQ)\n",
    "- `spline_order`: Higher = smoother, typically 3 (cubic) is a good choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
