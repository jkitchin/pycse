{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SISSO Demonstration: Symbolic Regression with Uncertainty Quantification\n",
    "\n",
    "This notebook demonstrates **SISSO (Sure Independence Screening and Sparsifying Operator)** for discovering interpretable analytical expressions from data with calibrated uncertainty estimates.\n",
    "\n",
    "## What is SISSO?\n",
    "\n",
    "SISSO is a symbolic regression method that:\n",
    "- Discovers **interpretable equations** (not black-box models)\n",
    "- Uses **feature construction** to build candidate expressions\n",
    "- Applies **sparsifying operators** to select the best terms\n",
    "- Provides **calibrated uncertainty** via the hat matrix method\n",
    "\n",
    "**Key Features of this wrapper:**\n",
    "- sklearn-compatible API (fit/predict/score)\n",
    "- Uncertainty quantification with `return_std=True`\n",
    "- Works with cross-validation and pipelines\n",
    "\n",
    "**Reference:** TorchSISSO - https://arxiv.org/abs/2410.01752"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "from pycse.sklearn import SISSO\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Discovering a Simple Equation\n",
    "\n",
    "Let's generate data from a known equation and see if SISSO can recover it.\n",
    "\n",
    "**True function:** y = 2*x0 + 3*x0*x1 - 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True function\n",
    "def true_function(X):\n",
    "    return 2 * X[:, 0] + 3 * X[:, 0] * X[:, 1] - 1.5\n",
    "\n",
    "\n",
    "# Generate training data\n",
    "n_train = 100\n",
    "X_train = np.random.rand(n_train, 2) * 2 - 1  # [-1, 1]\n",
    "noise = 0.1 * np.random.randn(n_train)\n",
    "y_train = true_function(X_train) + noise\n",
    "\n",
    "# Generate test data\n",
    "n_test = 50\n",
    "X_test = np.random.rand(n_test, 2) * 2 - 1\n",
    "y_test = true_function(X_test) + 0.1 * np.random.randn(n_test)\n",
    "\n",
    "print(f\"Training samples: {n_train}\")\n",
    "print(f\"Test samples: {n_test}\")\n",
    "print(\"True equation: y = 2*x0 + 3*x0*x1 - 1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Fit SISSO Model\n",
    "\n",
    "We use:\n",
    "- `n_expansion=2` to allow feature combinations like `x0*x1`\n",
    "- `n_term=2` to find a 2-term equation\n",
    "- Custom feature names for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SISSO(\n",
    "    operators=[\"+\", \"-\", \"*\", \"/\"], n_expansion=2, n_term=2, k=20, feature_names=[\"x0\", \"x1\"]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Discovered equation: {model.equation_}\")\n",
    "print(f\"Training R-squared: {model.r2_:.4f}\")\n",
    "print(f\"Training RMSE: {model.rmse_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Predictions with Uncertainty Quantification\n",
    "\n",
    "The `return_std=True` argument returns calibrated prediction uncertainties computed using the hat matrix method.\n",
    "\n",
    "### Theory\n",
    "\n",
    "Since SISSO's final model is a **linear combination of nonlinear features**:\n",
    "```\n",
    "y = c0 + c1*f1(x) + c2*f2(x) + ... + ct*ft(x)\n",
    "```\n",
    "\n",
    "We can use standard linear regression UQ via the **hat matrix**:\n",
    "- Residual variance: sigma^2 = RSS / (n - p)\n",
    "- Prediction variance: Var(y*) = sigma^2 * (1 + phi*^T (Phi^T Phi)^-1 phi*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Test R-squared: {test_r2:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Mean uncertainty: {np.mean(y_std):.4f}\")\n",
    "print(f\"Residual std (sigma): {model.sigma_:.4f}\")\n",
    "print(f\"Calibration factor: {model.calibration_factor_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Visualize Predictions vs True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Parity plot\n",
    "ax = axes[0]\n",
    "ax.errorbar(\n",
    "    y_test, y_pred, yerr=2 * y_std, fmt=\"o\", alpha=0.6, capsize=3, label=\"Predictions +/- 2 sigma\"\n",
    ")\n",
    "ax.plot(\n",
    "    [y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"k--\", label=\"Perfect prediction\"\n",
    ")\n",
    "ax.set_xlabel(\"True values\")\n",
    "ax.set_ylabel(\"Predicted values\")\n",
    "ax.set_title(\"Parity Plot with Uncertainty\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals with uncertainty bands\n",
    "ax = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax.errorbar(y_pred, residuals, yerr=2 * y_std, fmt=\"o\", alpha=0.6, capsize=3)\n",
    "ax.axhline(0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Predicted values\")\n",
    "ax.set_ylabel(\"Residuals\")\n",
    "ax.set_title(\"Residuals with Uncertainty Bands\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Checking Uncertainty Calibration\n",
    "\n",
    "For well-calibrated uncertainties:\n",
    "- ~68% of true values should fall within +/-1 sigma of predictions\n",
    "- ~95% should fall within +/-2 sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = (y_test - y_pred) / y_std\n",
    "\n",
    "coverage_1sigma = np.mean(np.abs(z_scores) < 1) * 100\n",
    "coverage_2sigma = np.mean(np.abs(z_scores) < 2) * 100\n",
    "\n",
    "print(f\"Coverage within +/-1 sigma: {coverage_1sigma:.1f}% (expected ~68%)\")\n",
    "print(f\"Coverage within +/-2 sigma: {coverage_2sigma:.1f}% (expected ~95%)\")\n",
    "\n",
    "# Plot z-score distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(z_scores, bins=15, density=True, alpha=0.7, label=\"Observed z-scores\")\n",
    "\n",
    "# Overlay standard normal\n",
    "x_norm = np.linspace(-4, 4, 100)\n",
    "y_norm = np.exp(-(x_norm**2) / 2) / np.sqrt(2 * np.pi)\n",
    "ax.plot(x_norm, y_norm, \"r-\", linewidth=2, label=\"Standard normal\")\n",
    "\n",
    "ax.set_xlabel(\"Z-score\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Calibration Check: Z-score Distribution\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Extrapolation: Uncertainty Should Increase\n",
    "\n",
    "When predicting outside the training domain, uncertainties should grow to reflect the model's reduced confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-distribution points\n",
    "X_in = np.random.rand(100, 2) * 2 - 1  # Same [-1, 1] range as training\n",
    "_, std_in = model.predict(X_in, return_std=True)\n",
    "\n",
    "# Out-of-distribution points (extrapolation)\n",
    "X_out = np.random.rand(100, 2) * 2 + 2  # [2, 4] range (outside training)\n",
    "_, std_out = model.predict(X_out, return_std=True)\n",
    "\n",
    "print(f\"Mean uncertainty (in-distribution): {np.mean(std_in):.4f}\")\n",
    "print(f\"Mean uncertainty (extrapolation): {np.mean(std_out):.4f}\")\n",
    "print(f\"Ratio: {np.mean(std_out) / np.mean(std_in):.2f}x\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(std_in, bins=20, alpha=0.6, label=\"In-distribution\", density=True)\n",
    "ax.hist(std_out, bins=20, alpha=0.6, label=\"Extrapolation\", density=True)\n",
    "ax.set_xlabel(\"Prediction uncertainty (sigma)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Uncertainty Distribution: In-domain vs Extrapolation\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Gaps in Training Data: Interpolation with UQ\n",
    "\n",
    "A key test of uncertainty quantification is how the model handles **gaps in training data**.\n",
    "The uncertainty should increase in regions where we have no training data.\n",
    "\n",
    "We'll test three functions with gaps, providing polynomial basis features where needed:\n",
    "1. **Linear**: y = 2x (SISSO can discover directly)\n",
    "2. **Quadratic**: y = 3x^2 + 1 (provide x^2 as feature)\n",
    "3. **Sine**: y = sin(x) (use polynomial approximation with x, x^2, x^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_with_gap(func, x_range, gap_start, gap_end, n_samples=100, noise_std=0.1):\n",
    "    \"\"\"Generate 1D data with a gap in the middle.\"\"\"\n",
    "    n_left = n_samples // 2\n",
    "    n_right = n_samples - n_left\n",
    "\n",
    "    x_left = np.linspace(x_range[0], gap_start, n_left)\n",
    "    x_right = np.linspace(gap_end, x_range[1], n_right)\n",
    "    x_train = np.concatenate([x_left, x_right])\n",
    "\n",
    "    y_true = func(x_train)\n",
    "    noise = noise_std * np.random.randn(len(x_train))\n",
    "    y_train = y_true + noise\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "# Define three test cases\n",
    "datasets = {\n",
    "    \"Linear: y = 2x\": {\n",
    "        \"func\": lambda x: 2 * x,\n",
    "        \"x_range\": (0, 1),\n",
    "        \"gap\": (0.35, 0.65),\n",
    "        \"noise\": 0.1,\n",
    "        \"make_features\": lambda x: x.reshape(-1, 1),  # Just x\n",
    "        \"feature_names\": [\"x\"],\n",
    "        \"n_term\": 1,\n",
    "        \"n_expansion\": 1,\n",
    "    },\n",
    "    \"Quadratic: y = 3x^2 + 1\": {\n",
    "        \"func\": lambda x: 3 * x**2 + 1,\n",
    "        \"x_range\": (-1, 1),\n",
    "        \"gap\": (-0.3, 0.3),\n",
    "        \"noise\": 0.15,\n",
    "        \"make_features\": lambda x: np.column_stack([x, x**2]),  # x and x^2\n",
    "        \"feature_names\": [\"x\", \"x_sq\"],\n",
    "        \"n_term\": 1,\n",
    "        \"n_expansion\": 1,\n",
    "    },\n",
    "    \"Sine: y = sin(x)\": {\n",
    "        \"func\": np.sin,\n",
    "        \"x_range\": (0, 2 * np.pi),\n",
    "        \"gap\": (2.5, 4.0),\n",
    "        \"noise\": 0.1,\n",
    "        \"make_features\": lambda x: np.column_stack([x, x**2, x**3]),  # Polynomial basis\n",
    "        \"feature_names\": [\"x\", \"x2\", \"x3\"],\n",
    "        \"n_term\": 3,\n",
    "        \"n_expansion\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Generated datasets with gaps:\")\n",
    "for name, params in datasets.items():\n",
    "    print(f\"  - {name}: gap at [{params['gap'][0]:.2f}, {params['gap'][1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SISSO models and plot results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "for idx, (name, params) in enumerate(datasets.items()):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Generate data with gap\n",
    "    np.random.seed(42)\n",
    "    x_train, y_train = generate_data_with_gap(\n",
    "        params[\"func\"],\n",
    "        params[\"x_range\"],\n",
    "        params[\"gap\"][0],\n",
    "        params[\"gap\"][1],\n",
    "        n_samples=100,\n",
    "        noise_std=params[\"noise\"],\n",
    "    )\n",
    "\n",
    "    # Create features\n",
    "    X_train = params[\"make_features\"](x_train)\n",
    "\n",
    "    # Fit SISSO\n",
    "    model = SISSO(\n",
    "        operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "        n_expansion=params[\"n_expansion\"],\n",
    "        n_term=params[\"n_term\"],\n",
    "        k=20,\n",
    "        feature_names=params[\"feature_names\"],\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Create dense prediction grid\n",
    "    x_plot = np.linspace(params[\"x_range\"][0], params[\"x_range\"][1], 200)\n",
    "    X_plot = params[\"make_features\"](x_plot)\n",
    "\n",
    "    # Predict with uncertainty\n",
    "    y_pred, y_std = model.predict(X_plot, return_std=True)\n",
    "\n",
    "    # True function for comparison\n",
    "    y_true = params[\"func\"](x_plot)\n",
    "\n",
    "    # Calculate MAE\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    mae = np.mean(np.abs(y_train - y_pred_train))\n",
    "\n",
    "    # Plot uncertainty band\n",
    "    ax.fill_between(\n",
    "        x_plot, y_pred - 2 * y_std, y_pred + 2 * y_std, alpha=0.3, color=\"red\", label=\"95% CI\"\n",
    "    )\n",
    "\n",
    "    # Plot prediction\n",
    "    ax.plot(x_plot, y_pred, \"r-\", linewidth=2, label=\"SISSO prediction\")\n",
    "\n",
    "    # Plot true function\n",
    "    ax.plot(x_plot, y_true, \"gray\", linewidth=1, linestyle=\"--\", alpha=0.5, label=\"True function\")\n",
    "\n",
    "    # Plot training data\n",
    "    ax.scatter(x_train, y_train, c=\"dimgray\", s=30, alpha=0.6, marker=\"s\", label=\"Training data\")\n",
    "\n",
    "    # Shade gap region\n",
    "    ax.axvspan(params[\"gap\"][0], params[\"gap\"][1], alpha=0.1, color=\"purple\")\n",
    "\n",
    "    # Add MAE annotation\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        f\"MAE={mae:.3f}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    eq_display = model.equation_[:50] + \"...\" if len(model.equation_) > 50 else model.equation_\n",
    "    ax.set_title(f\"{name}\\nEquation: {eq_display}\")\n",
    "    ax.legend(loc=\"best\", fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: The purple shaded region shows the gap where no training data exists.\")\n",
    "print(\"Uncertainty bands reflect the model's confidence based on the discovered equation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Detailed Gap Analysis\n",
    "\n",
    "Let's quantify how uncertainty behaves in different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the quadratic case in detail\n",
    "np.random.seed(42)\n",
    "params = datasets[\"Quadratic: y = 3x^2 + 1\"]\n",
    "\n",
    "x_train, y_train = generate_data_with_gap(\n",
    "    params[\"func\"],\n",
    "    params[\"x_range\"],\n",
    "    params[\"gap\"][0],\n",
    "    params[\"gap\"][1],\n",
    "    n_samples=100,\n",
    "    noise_std=params[\"noise\"],\n",
    ")\n",
    "\n",
    "X_train = params[\"make_features\"](x_train)\n",
    "\n",
    "model = SISSO(\n",
    "    operators=[\"+\", \"-\", \"*\", \"/\"], n_expansion=1, n_term=1, k=20, feature_names=[\"x\", \"x_sq\"]\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Sample points inside gap, outside gap, and extrapolation\n",
    "x_in_gap = np.linspace(-0.25, 0.25, 50)\n",
    "x_outside_gap = np.concatenate([np.linspace(-0.9, -0.4, 25), np.linspace(0.4, 0.9, 25)])\n",
    "x_extrap = np.concatenate([np.linspace(-2, -1.1, 25), np.linspace(1.1, 2, 25)])\n",
    "\n",
    "_, std_in_gap = model.predict(params[\"make_features\"](x_in_gap), return_std=True)\n",
    "_, std_outside_gap = model.predict(params[\"make_features\"](x_outside_gap), return_std=True)\n",
    "_, std_extrap = model.predict(params[\"make_features\"](x_extrap), return_std=True)\n",
    "\n",
    "print(\"Quadratic function uncertainty analysis:\")\n",
    "print(f\"  Discovered equation: {model.equation_}\")\n",
    "print(\"\\nMean uncertainty by region:\")\n",
    "print(f\"  In gap [-0.3, 0.3]:     {np.mean(std_in_gap):.4f}\")\n",
    "print(f\"  Training region:        {np.mean(std_outside_gap):.4f}\")\n",
    "print(f\"  Extrapolation:          {np.mean(std_extrap):.4f}\")\n",
    "print(\"\\nRatios:\")\n",
    "print(f\"  Extrapolation / Training: {np.mean(std_extrap) / np.mean(std_outside_gap):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Example: Discovering a Physical Law\n",
    "\n",
    "Let's try to discover the equation for kinetic energy:\n",
    "\n",
    "**E = 0.5 * m * v^2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate physics data\n",
    "n = 100\n",
    "mass = np.random.uniform(1, 10, n)  # kg\n",
    "velocity = np.random.uniform(0, 20, n)  # m/s\n",
    "energy = 0.5 * mass * velocity**2  # True kinetic energy\n",
    "energy_noisy = energy + 0.05 * energy * np.random.randn(n)  # 5% noise\n",
    "\n",
    "# Include m, v, and v^2 as features\n",
    "X_physics = np.column_stack([mass, velocity, velocity**2])\n",
    "y_physics = energy_noisy\n",
    "\n",
    "# Fit SISSO\n",
    "model_physics = SISSO(\n",
    "    operators=[\"+\", \"-\", \"*\", \"/\"], n_expansion=1, n_term=1, k=20, feature_names=[\"m\", \"v\", \"v_sq\"]\n",
    ")\n",
    "model_physics.fit(X_physics, y_physics)\n",
    "\n",
    "print(\"True equation: E = 0.5 * m * v^2\")\n",
    "print(f\"Discovered: {model_physics.equation_}\")\n",
    "print(f\"R-squared: {model_physics.r2_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 10. sklearn Compatibility\n",
    "\n",
    "SISSO works with sklearn's model selection and pipeline tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on 2D data\n",
    "np.random.seed(42)\n",
    "X_cv = np.random.rand(100, 2)\n",
    "y_cv = X_cv[:, 0] + X_cv[:, 1] + 0.1 * np.random.randn(100)\n",
    "\n",
    "model_cv = SISSO(n_expansion=1, n_term=1, feature_names=[\"x0\", \"x1\"])\n",
    "scores = cross_val_score(model_cv, X_cv, y_cv, cv=3, scoring=\"r2\")\n",
    "print(f\"Cross-validation R-squared scores: {scores}\")\n",
    "print(f\"Mean CV R-squared: {scores.mean():.4f} +/- {scores.std():.4f}\")\n",
    "\n",
    "# Clone test\n",
    "cloned = clone(model)\n",
    "print(\"\\nCloned model parameters:\")\n",
    "print(f\"  n_expansion={cloned.n_expansion}\")\n",
    "print(f\"  n_term={cloned.n_term}\")\n",
    "print(f\"  k={cloned.k}\")\n",
    "\n",
    "# Get/set params\n",
    "params = model.get_params()\n",
    "print(f\"\\nAll parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "The `SISSO` estimator provides:\n",
    "\n",
    "1. **Interpretable equations** - Discovers symbolic expressions, not black boxes\n",
    "2. **sklearn compatibility** - Works with cross-validation, pipelines, etc.\n",
    "3. **Calibrated uncertainty** - Hat matrix method with empirical calibration\n",
    "4. **Extrapolation awareness** - Uncertainty grows outside training domain\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `operators` | List of operators: `['+', '-', '*', '/']`, optionally `'exp'`, `'ln'`, etc. |\n",
    "| `n_expansion` | Feature expansion depth (2-3 typical) |\n",
    "| `n_term` | Number of terms in equation (1-3 typical) |\n",
    "| `k` | Features kept per screening iteration |\n",
    "| `feature_names` | Names for interpretable equations |\n",
    "\n",
    "### Tips for Feature Engineering\n",
    "\n",
    "SISSO discovers equations as linear combinations of constructed features. For best results:\n",
    "- With multiple features (x0, x1), SISSO can discover products like x0*x1\n",
    "- For polynomial terms (x^2, x^3), provide them explicitly as features\n",
    "- Use meaningful feature names for interpretable equations\n",
    "\n",
    "### Usage Pattern\n",
    "\n",
    "```python\n",
    "from pycse.sklearn import SISSO\n",
    "\n",
    "# Fit model\n",
    "model = SISSO(\n",
    "    operators=['+', '-', '*', '/'],\n",
    "    n_expansion=2,\n",
    "    n_term=2,\n",
    "    feature_names=['x', 'y', 'z']\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get discovered equation\n",
    "print(model.equation_)\n",
    "\n",
    "# Predict with uncertainty\n",
    "y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "```\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install pycse[sisso]\n",
    "# or\n",
    "pip install TorchSisso\n",
    "```\n",
    "\n",
    "### References\n",
    "\n",
    "- [TorchSISSO Paper](https://arxiv.org/abs/2410.01752)\n",
    "- [TorchSISSO GitHub](https://github.com/PaulsonLab/TorchSISSO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
