{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SISSOEnsemble Demonstration: Interpretable Symbolic Regression with Calibrated UQ\n",
    "\n",
    "This notebook demonstrates **SISSOEnsemble** - a shallow ensemble of SISSO equations with calibrated uncertainty quantification.\n",
    "\n",
    "## What is SISSOEnsemble?\n",
    "\n",
    "SISSOEnsemble combines:\n",
    "- **SISSO** (Sure Independence Screening and Sparsifying Operator) for discovering interpretable symbolic equations\n",
    "- **DPOSE-style shallow ensembles** for calibrated uncertainty quantification\n",
    "\n",
    "Key features:\n",
    "- âœ… **Interpretable equations** - each ensemble member is a readable symbolic expression\n",
    "- âœ… **Calibrated uncertainties** - trained with CRPS or NLL loss\n",
    "- âœ… **Ensemble diversity** - different equation complexities (n_term values)\n",
    "- âœ… **Post-hoc calibration** - optional validation-based calibration\n",
    "- âœ… **Uncertainty propagation** - via `predict_ensemble()`\n",
    "\n",
    "**References:**\n",
    "- TorchSISSO: https://arxiv.org/abs/2410.01752\n",
    "- DPOSE: Kellner & Ceriotti (2024), *Machine Learning: Science and Technology*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print('Imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Basic Example: Simple Additive Function\n",
    "\n",
    "Let's start with a simple example where the true function is `y = x0 + x1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycse.sklearn import SISSOEnsemble\n",
    "\n",
    "# Generate simple additive data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)\n",
    "y = X[:, 0] + X[:, 1] + 0.05 * np.random.randn(100)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Test samples: {len(X_test)}')\n",
    "print(f'True function: y = x0 + x1 + noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SISSOEnsemble\n",
    "model = SISSOEnsemble(\n",
    "    n_models=5,           # Number of equations to discover\n",
    "    n_expansion=1,        # Feature expansion depth\n",
    "    n_terms_range=(1, 3), # Range of terms per equation\n",
    "    loss_type='crps',     # CRPS loss for calibrated uncertainties\n",
    "    feature_names=['x0', 'x1']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\nDiscovered {model.n_ensemble_} unique equations:')\n",
    "for i, eq in enumerate(model.equations_):\n",
    "    print(f'  {i+1}. {eq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print('Test Set Performance:')\n",
    "print(f'  MAE:  {mae:.6f}')\n",
    "print(f'  RMSE: {rmse:.6f}')\n",
    "print(f'  RÂ²:   {r2:.6f}')\n",
    "print(f'  Uncertainty range: [{y_std.min():.4f}, {y_std.max():.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Interpolation and Extrapolation with Gaps\n",
    "\n",
    "A key test for uncertainty quantification is how the model behaves:\n",
    "- **In gaps**: regions without training data (interpolation)\n",
    "- **Beyond data range**: extrapolation\n",
    "\n",
    "Good UQ should show increased uncertainty in these regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1D data with a gap in the middle\n",
    "np.random.seed(42)\n",
    "\n",
    "# Left region: [0, 0.35]\n",
    "x_left = np.linspace(0, 0.35, 40)[:, None]\n",
    "# Right region: [0.65, 1]\n",
    "x_right = np.linspace(0.65, 1, 40)[:, None]\n",
    "\n",
    "# Combine (gap in middle: [0.35, 0.65])\n",
    "X_train = np.vstack([x_left, x_right])\n",
    "\n",
    "# True function: quadratic\n",
    "y_train = 2 * X_train.ravel()**2 + X_train.ravel() + 0.05 * np.random.randn(len(X_train))\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Data range: [0, 0.35] âˆª [0.65, 1]')\n",
    "print(f'Gap: [0.35, 0.65]')\n",
    "print(f'True function: y = 2xÂ² + x + noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SISSOEnsemble\n",
    "model_gap = SISSOEnsemble(\n",
    "    n_models=5,\n",
    "    n_expansion=2,        # Allow xÂ², x*x, etc.\n",
    "    n_terms_range=(1, 3),\n",
    "    loss_type='crps',\n",
    "    feature_names=['x']\n",
    ")\n",
    "\n",
    "model_gap.fit(X_train, y_train)\n",
    "\n",
    "print(f'Discovered {model_gap.n_ensemble_} equations:')\n",
    "for i, eq in enumerate(model_gap.equations_):\n",
    "    print(f'  {i+1}. {eq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict over extended range (including gap and extrapolation)\n",
    "x_plot = np.linspace(-0.3, 1.3, 200)[:, None]\n",
    "y_pred, y_std = model_gap.predict(x_plot, return_std=True)\n",
    "\n",
    "# True function for comparison\n",
    "y_true = 2 * x_plot.ravel()**2 + x_plot.ravel()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Extrapolation regions\n",
    "ax.axvspan(-0.3, 0, alpha=0.15, color='orange', label='Extrapolation')\n",
    "ax.axvspan(1, 1.3, alpha=0.15, color='orange')\n",
    "\n",
    "# Gap region\n",
    "ax.axvspan(0.35, 0.65, alpha=0.15, color='purple', label='Gap (interpolation)')\n",
    "\n",
    "# Uncertainty band\n",
    "ax.fill_between(x_plot.ravel(), y_pred - 2*y_std, y_pred + 2*y_std,\n",
    "                alpha=0.3, color='red', label='Â±2Ïƒ (95% CI)')\n",
    "\n",
    "# Predictions\n",
    "ax.plot(x_plot.ravel(), y_pred, 'r-', linewidth=2.5, label='SISSOEnsemble')\n",
    "ax.plot(x_plot.ravel(), y_true, 'k--', linewidth=1.5, label='True function', alpha=0.7)\n",
    "\n",
    "# Training data\n",
    "ax.scatter(X_train, y_train, c='blue', s=40, alpha=0.6, label='Training data', zorder=5)\n",
    "\n",
    "# Data boundaries\n",
    "ax.axvline(0, color='black', linestyle='--', alpha=0.3)\n",
    "ax.axvline(1, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('SISSOEnsemble: Interpolation in Gap & Extrapolation', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=10, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nKey observations:')\n",
    "print('  â€¢ Orange regions: Extrapolation beyond training data')\n",
    "print('  â€¢ Purple region: Gap where no training data exists')\n",
    "print('  â€¢ Uncertainty band (red) should widen in gap and extrapolation regions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Comparing Loss Functions: CRPS vs NLL vs MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loss functions\n",
    "loss_types = ['crps', 'nll', 'mse']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, loss_type in enumerate(loss_types):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Fit model\n",
    "    model_loss = SISSOEnsemble(\n",
    "        n_models=5,\n",
    "        n_expansion=2,\n",
    "        n_terms_range=(1, 3),\n",
    "        loss_type=loss_type,\n",
    "        feature_names=['x']\n",
    "    )\n",
    "    model_loss.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred, y_std = model_loss.predict(x_plot, return_std=True)\n",
    "    \n",
    "    # Plot regions\n",
    "    ax.axvspan(-0.3, 0, alpha=0.1, color='orange')\n",
    "    ax.axvspan(1, 1.3, alpha=0.1, color='orange')\n",
    "    ax.axvspan(0.35, 0.65, alpha=0.1, color='purple')\n",
    "    \n",
    "    # Uncertainty and prediction\n",
    "    ax.fill_between(x_plot.ravel(), y_pred - 2*y_std, y_pred + 2*y_std,\n",
    "                    alpha=0.3, color='red', label='Â±2Ïƒ')\n",
    "    ax.plot(x_plot.ravel(), y_pred, 'r-', linewidth=2, label='Prediction')\n",
    "    ax.plot(x_plot.ravel(), y_true, 'k--', linewidth=1, label='True', alpha=0.5)\n",
    "    ax.scatter(X_train, y_train, c='blue', s=20, alpha=0.5, label='Data')\n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f'{loss_type.upper()} Loss\\nÏƒ âˆˆ [{y_std.min():.3f}, {y_std.max():.3f}]')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nLoss function comparison:')\n",
    "print('  CRPS: Robust, single-stage training (recommended)')\n",
    "print('  NLL:  Can capture heteroscedasticity well')\n",
    "print('  MSE:  No uncertainty training (baseline)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Post-hoc Calibration with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate more data for validation\n",
    "np.random.seed(123)\n",
    "X_full = np.random.rand(150, 2)\n",
    "y_full = X_full[:, 0] + 2*X_full[:, 1] + 0.1 * np.random.randn(150)\n",
    "\n",
    "# Split into train/val/test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_full, y_full, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Training: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit without calibration\n",
    "model_uncalib = SISSOEnsemble(\n",
    "    n_models=5, n_expansion=1, n_terms_range=(1, 3),\n",
    "    feature_names=['x0', 'x1']\n",
    ")\n",
    "model_uncalib.fit(X_train, y_train)\n",
    "\n",
    "# Fit with calibration\n",
    "model_calib = SISSOEnsemble(\n",
    "    n_models=5, n_expansion=1, n_terms_range=(1, 3),\n",
    "    feature_names=['x0', 'x1']\n",
    ")\n",
    "model_calib.fit(X_train, y_train, val_X=X_val, val_y=y_val)\n",
    "\n",
    "print(f'Uncalibrated model calibration factor: {model_uncalib.calibration_factor_:.4f}')\n",
    "print(f'Calibrated model calibration factor: {model_calib.calibration_factor_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare on test set\n",
    "y_pred_uncalib, y_std_uncalib = model_uncalib.predict(X_test, return_std=True)\n",
    "y_pred_calib, y_std_calib = model_calib.predict(X_test, return_std=True)\n",
    "\n",
    "# Z-scores (should have std ~1 if well-calibrated)\n",
    "z_uncalib = (y_test - y_pred_uncalib) / y_std_uncalib\n",
    "z_calib = (y_test - y_pred_calib) / y_std_calib\n",
    "\n",
    "print('Calibration Quality (Z-score std should be ~1.0):')\n",
    "print(f'  Uncalibrated: Z-score std = {np.std(z_uncalib):.4f}')\n",
    "print(f'  Calibrated:   Z-score std = {np.std(z_calib):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Ensemble Predictions for Uncertainty Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full ensemble predictions\n",
    "ensemble_preds = model_calib.predict_ensemble(X_test)\n",
    "\n",
    "print(f'Ensemble predictions shape: {ensemble_preds.shape}')\n",
    "print(f'  {len(X_test)} samples Ã— {model_calib.n_ensemble_} ensemble members')\n",
    "\n",
    "# Each column is a different equation's prediction\n",
    "print(f'\\nPrediction range per ensemble member:')\n",
    "for i in range(ensemble_preds.shape[1]):\n",
    "    print(f'  Member {i+1}: [{ensemble_preds[:, i].min():.3f}, {ensemble_preds[:, i].max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty propagation example: z = exp(y)\n",
    "z_ensemble = np.exp(ensemble_preds)\n",
    "z_mean = z_ensemble.mean(axis=1)\n",
    "z_std = z_ensemble.std(axis=1)\n",
    "\n",
    "# Compare with naive propagation\n",
    "y_mean, y_std = model_calib.predict(X_test, return_std=True)\n",
    "z_mean_naive = np.exp(y_mean)\n",
    "z_std_naive = z_mean_naive * y_std  # Linear approximation: dz/dy * dy\n",
    "\n",
    "print('Uncertainty propagation through z = exp(y):')\n",
    "print(f'  Ensemble method:  z_std âˆˆ [{z_std.min():.4f}, {z_std.max():.4f}]')\n",
    "print(f'  Naive (linear):   z_std âˆˆ [{z_std_naive.min():.4f}, {z_std_naive.max():.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 6. Viewing the Discovered Equations\n",
    "\n",
    "A key advantage of SISSOEnsemble over neural network ensembles is **interpretability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display discovered equations\n",
    "print('Discovered Symbolic Equations:')\n",
    "print('=' * 60)\n",
    "for i, eq in enumerate(model_calib.equations_):\n",
    "    print(f'Equation {i+1}: {eq}')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\nTrue function: y = x0 + 2*x1')\n",
    "print('\\nNote: Each equation provides a different symbolic approximation.')\n",
    "print('The ensemble combines them for robust predictions with uncertainty.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "### What SISSOEnsemble Provides\n",
    "\n",
    "1. **Interpretable Equations**\n",
    "   - Each ensemble member is a readable symbolic expression\n",
    "   - Useful for understanding the underlying relationship\n",
    "\n",
    "2. **Calibrated Uncertainties**\n",
    "   - CRPS/NLL training for well-calibrated predictions\n",
    "   - Optional post-hoc calibration with validation data\n",
    "\n",
    "3. **Gap and Extrapolation Handling**\n",
    "   - Uncertainty increases appropriately in sparse regions\n",
    "   - Ensemble diversity provides robustness\n",
    "\n",
    "4. **Uncertainty Propagation**\n",
    "   - Use `predict_ensemble()` for derived quantities\n",
    "   - Apply any transformation to ensemble members\n",
    "\n",
    "### Recommended Usage\n",
    "\n",
    "```python\n",
    "from pycse.sklearn import SISSOEnsemble\n",
    "\n",
    "# Basic usage\n",
    "model = SISSOEnsemble(\n",
    "    n_models=5,           # Number of equations\n",
    "    n_expansion=2,        # Feature complexity\n",
    "    n_terms_range=(1, 3), # Terms per equation\n",
    "    loss_type='crps',     # Robust loss function\n",
    "    feature_names=['x0', 'x1', 'x2']\n",
    ")\n",
    "\n",
    "# Fit with optional calibration\n",
    "model.fit(X_train, y_train, val_X=X_val, val_y=y_val)\n",
    "\n",
    "# Predict with uncertainty\n",
    "y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "\n",
    "# View equations\n",
    "for eq in model.equations_:\n",
    "    print(eq)\n",
    "\n",
    "# Uncertainty propagation\n",
    "ensemble = model.predict_ensemble(X_test)\n",
    "z_ensemble = f(ensemble)  # Apply your function\n",
    "z_mean, z_std = z_ensemble.mean(axis=1), z_ensemble.std(axis=1)\n",
    "```\n",
    "\n",
    "### When to Use SISSOEnsemble\n",
    "\n",
    "- When you need **interpretable models** (symbolic equations)\n",
    "- When you want **calibrated uncertainty quantification**\n",
    "- When data is limited and **extrapolation awareness** is important\n",
    "- When you need to **propagate uncertainties** through derived quantities\n",
    "\n",
    "---\n",
    "\n",
    "**Enjoy interpretable symbolic regression with calibrated UQ!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
