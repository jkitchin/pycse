{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# JAXPeriodicRegressor: Periodic Neural Networks with Uncertainty\n",
    "\n",
    "This notebook demonstrates using Periodic Neural Networks for regression tasks where inputs have known periodicity, such as angles, phases, or cyclic time features.\n",
    "\n",
    "## What are Periodic Neural Networks?\n",
    "\n",
    "Periodic Neural Networks use **Fourier feature expansion** to capture periodic patterns. For a feature $x$ with period $T$, we expand it as:\n",
    "\n",
    "$$\\phi(x) = [\\sin(2\\pi x/T), \\cos(2\\pi x/T), \\sin(4\\pi x/T), \\cos(4\\pi x/T), \\ldots]$$\n",
    "\n",
    "This representation guarantees that the network output is **exactly periodic** with period $T$:\n",
    "\n",
    "$$f(x + T) = f(x) \\quad \\text{for all } x$$\n",
    "\n",
    "## When to Use Periodic Neural Networks\n",
    "\n",
    "Periodic features arise naturally in many domains:\n",
    "\n",
    "| Domain | Example | Period |\n",
    "|--------|---------|--------|\n",
    "| Chemistry | Dihedral angles | $2\\pi$ |\n",
    "| Materials | Crystallographic angles | $2\\pi$ or lattice-specific |\n",
    "| Time series | Hour of day | 24 hours |\n",
    "| Time series | Day of year | 365 days |\n",
    "| Physics | Phase angles | $2\\pi$ |\n",
    "| Signal processing | Wave phases | Signal-specific |\n",
    "\n",
    "## References\n",
    "\n",
    "- Rahimi, A., & Recht, B. (2007). \"Random Features for Large-Scale Kernel Machines.\" NIPS.\n",
    "- Tancik, M., et al. (2020). \"Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains.\" NeurIPS.\n",
    "\n",
    "## LLPR Uncertainty Quantification\n",
    "\n",
    "This implementation includes **Last-Layer Prediction Rigidity (LLPR)** for uncertainty quantification:\n",
    "\n",
    "- Bigi, F., Chong, S., Ceriotti, M., & Grasselli, F. (2024). \"A prediction rigidity formalism for low-cost uncertainties in trained neural networks.\" Machine Learning: Science and Technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "from pycse.sklearn.jax_periodic import JAXPeriodicRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## How Fourier Features Guarantee Periodicity\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "The trigonometric functions $\\sin$ and $\\cos$ are periodic with period $2\\pi$. By computing:\n",
    "\n",
    "$$\\sin(2\\pi x / T) \\quad \\text{and} \\quad \\cos(2\\pi x / T)$$\n",
    "\n",
    "we get functions that are periodic with period $T$:\n",
    "\n",
    "$$\\sin(2\\pi(x+T)/T) = \\sin(2\\pi x/T + 2\\pi) = \\sin(2\\pi x/T)$$\n",
    "\n",
    "### Multiple Harmonics\n",
    "\n",
    "Using multiple harmonics allows the network to capture complex periodic patterns:\n",
    "\n",
    "$$\\phi(x) = [\\sin(\\omega x), \\cos(\\omega x), \\sin(2\\omega x), \\cos(2\\omega x), \\ldots, \\sin(n\\omega x), \\cos(n\\omega x)]$$\n",
    "\n",
    "where $\\omega = 2\\pi/T$ is the fundamental frequency.\n",
    "\n",
    "**More harmonics = more complex patterns, but also more parameters and potential overfitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Fourier features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# 1. Single harmonic\n",
    "x = np.linspace(0, 4 * np.pi, 200)\n",
    "T = 2 * np.pi\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(x, np.sin(2 * np.pi * x / T), \"b-\", linewidth=2, label=\"sin(2πx/T)\")\n",
    "ax.plot(x, np.cos(2 * np.pi * x / T), \"r-\", linewidth=2, label=\"cos(2πx/T)\")\n",
    "ax.axvline(T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axvline(2 * T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Feature value\")\n",
    "ax.set_title(f\"First Harmonic (T={T:.2f})\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Multiple harmonics\n",
    "ax = axes[1]\n",
    "for n in range(1, 4):\n",
    "    ax.plot(x, np.sin(2 * np.pi * n * x / T), linewidth=2, label=f\"sin({n}·2πx/T)\")\n",
    "ax.axvline(T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axvline(2 * T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Feature value\")\n",
    "ax.set_title(\"Multiple Harmonics\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Complex periodic function from harmonics\n",
    "ax = axes[2]\n",
    "complex_periodic = (\n",
    "    0.5 * np.sin(2 * np.pi * x / T)\n",
    "    + 0.3 * np.cos(4 * np.pi * x / T)\n",
    "    + 0.2 * np.sin(6 * np.pi * x / T)\n",
    ")\n",
    "ax.plot(x, complex_periodic, \"purple\", linewidth=2)\n",
    "ax.axvline(T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axvline(2 * T, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "ax.set_title(\"Complex Periodic Function\\n(Linear combination of harmonics)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key insight: Any periodic function with period T can be approximated\")\n",
    "print(\"by a linear combination of sin and cos at harmonics of T.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. Basic Usage: Learning a Sine Function\n",
    "\n",
    "Let's start with a simple example: learning $y = \\sin(x)$ from noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from a simple periodic function\n",
    "np.random.seed(42)\n",
    "n_samples = 150\n",
    "\n",
    "# Sample within one period, but we want to extrapolate to multiple periods\n",
    "X_train_range = np.random.uniform(0, 2 * np.pi, (n_samples, 1))\n",
    "y_train_range = np.sin(X_train_range[:, 0]) + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "print(f\"Training samples: {n_samples}\")\n",
    "print(\"Training range: [0, 2π]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train periodic model\n",
    "model = JAXPeriodicRegressor(\n",
    "    hidden_dims=(32, 32),\n",
    "    periodicity={0: 2 * np.pi},  # Feature 0 has period 2π\n",
    "    n_harmonics=5,\n",
    "    epochs=500,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "model.fit(X_train_range, y_train_range)\n",
    "\n",
    "print(f\"\\nNumber of expanded features: {model.n_expanded_features_}\")\n",
    "print(\"  (5 harmonics × 2 [sin+cos] = 10 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test periodicity by predicting over multiple periods\n",
    "X_test_extended = np.linspace(-2 * np.pi, 4 * np.pi, 300).reshape(-1, 1)\n",
    "y_pred_extended = model.predict(X_test_extended)\n",
    "y_true = np.sin(X_test_extended[:, 0])\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.fill_between([-2 * np.pi, 0], -2, 2, alpha=0.1, color=\"red\", label=\"Extrapolation region\")\n",
    "plt.fill_between([2 * np.pi, 4 * np.pi], -2, 2, alpha=0.1, color=\"red\")\n",
    "plt.fill_between([0, 2 * np.pi], -2, 2, alpha=0.1, color=\"green\", label=\"Training region\")\n",
    "\n",
    "plt.plot(X_test_extended, y_true, \"k--\", linewidth=1.5, label=\"True: sin(x)\")\n",
    "plt.plot(X_test_extended, y_pred_extended, \"b-\", linewidth=2, label=\"Periodic NN\")\n",
    "plt.scatter(X_train_range, y_train_range, alpha=0.3, c=\"gray\", s=20, label=\"Training data\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Periodic Neural Network: Perfect Extrapolation\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: The model perfectly extrapolates outside the training region!\")\n",
    "print(\"This is because periodicity is built into the representation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify exact periodicity\n",
    "x_base = np.array([[0.5], [1.0], [2.0], [3.0]])\n",
    "x_shifted = x_base + 2 * np.pi  # Shift by one period\n",
    "x_shifted_2 = x_base + 4 * np.pi  # Shift by two periods\n",
    "\n",
    "y_base = model.predict(x_base)\n",
    "y_shifted = model.predict(x_shifted)\n",
    "y_shifted_2 = model.predict(x_shifted_2)\n",
    "\n",
    "print(\"Periodicity verification:\")\n",
    "print(\"\\n  x       f(x)     f(x+2π)   f(x+4π)   Diff\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "for i in range(len(x_base)):\n",
    "    diff = max(abs(y_base[i] - y_shifted[i]), abs(y_base[i] - y_shifted_2[i]))\n",
    "    print(\n",
    "        f\"  {x_base[i, 0]:.2f}    {y_base[i]:7.4f}   {y_shifted[i]:7.4f}   {y_shifted_2[i]:7.4f}   {diff:.2e}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nPredictions at x, x+2π, and x+4π are identical (to machine precision)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 2. Complex Periodic Functions\n",
    "\n",
    "The Fourier representation can capture complex periodic patterns, not just simple sines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complex periodic data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "X_complex = np.random.uniform(0, 2 * np.pi, (n_samples, 1))\n",
    "# A more complex periodic function\n",
    "y_complex = (\n",
    "    np.sin(X_complex[:, 0])\n",
    "    + 0.5 * np.cos(2 * X_complex[:, 0])\n",
    "    + 0.3 * np.sin(3 * X_complex[:, 0])\n",
    "    + 0.1 * np.random.randn(n_samples)\n",
    ")\n",
    "\n",
    "# Train with different numbers of harmonics\n",
    "models = {}\n",
    "for n_harm in [1, 3, 5, 10]:\n",
    "    m = JAXPeriodicRegressor(\n",
    "        hidden_dims=(32, 32),\n",
    "        periodicity={0: 2 * np.pi},\n",
    "        n_harmonics=n_harm,\n",
    "        epochs=300,\n",
    "        random_state=42,\n",
    "    )\n",
    "    m.fit(X_complex, y_complex)\n",
    "    models[n_harm] = m\n",
    "    print(f\"n_harmonics={n_harm}: R² = {m.score(X_complex, y_complex):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different numbers of harmonics\n",
    "X_plot = np.linspace(0, 2 * np.pi, 200).reshape(-1, 1)\n",
    "y_true_complex = (\n",
    "    np.sin(X_plot[:, 0]) + 0.5 * np.cos(2 * X_plot[:, 0]) + 0.3 * np.sin(3 * X_plot[:, 0])\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, n_harm in zip(axes.flat, [1, 3, 5, 10]):\n",
    "    y_pred = models[n_harm].predict(X_plot)\n",
    "\n",
    "    ax.plot(X_plot, y_true_complex, \"k--\", linewidth=1.5, label=\"True function\")\n",
    "    ax.plot(X_plot, y_pred, \"b-\", linewidth=2, label=\"Periodic NN\")\n",
    "    ax.scatter(X_complex, y_complex, alpha=0.2, c=\"gray\", s=10)\n",
    "\n",
    "    r2 = models[n_harm].score(X_complex, y_complex)\n",
    "    n_features = models[n_harm].n_expanded_features_\n",
    "    ax.set_title(f\"{n_harm} harmonics ({n_features} features), R²={r2:.4f}\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Effect of Number of Harmonics\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"More harmonics = better fit for complex patterns\")\n",
    "print(\"But also more parameters (potential overfitting with limited data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 3. Mixed Periodic and Non-Periodic Features\n",
    "\n",
    "In many applications, some features are periodic (like angles) while others are not (like temperature or pressure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with mixed features\n",
    "# Example: Material property as function of angle (periodic) and temperature (non-periodic)\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "\n",
    "angle = np.random.uniform(0, 2 * np.pi, n_samples)  # Periodic\n",
    "temperature = np.random.uniform(300, 600, n_samples)  # Non-periodic (Kelvin)\n",
    "\n",
    "X_mixed = np.column_stack([angle, temperature])\n",
    "\n",
    "# Property depends on both:\n",
    "# - Periodic in angle (e.g., crystallographic orientation)\n",
    "# - Linear in temperature\n",
    "y_mixed = (\n",
    "    np.cos(angle)  # Periodic dependence\n",
    "    + 0.01 * (temperature - 450)  # Linear temperature dependence\n",
    "    + 0.1 * np.random.randn(n_samples)\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_mixed, y_mixed, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Features:\")\n",
    "print(\"  x0: Angle (radians) - PERIODIC with period 2π\")\n",
    "print(\"  x1: Temperature (K) - NON-PERIODIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with mixed periodicity\n",
    "model_mixed = JAXPeriodicRegressor(\n",
    "    hidden_dims=(32, 32),\n",
    "    periodicity={0: 2 * np.pi},  # Only angle is periodic\n",
    "    n_harmonics=3,\n",
    "    epochs=500,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "model_mixed.fit(X_train, y_train)\n",
    "\n",
    "r2 = model_mixed.score(X_test, y_test)\n",
    "print(f\"\\nR² score on test set: {r2:.4f}\")\n",
    "print(f\"\\nExpanded features: {model_mixed.n_expanded_features_}\")\n",
    "print(\"  Angle: 3 harmonics × 2 = 6 features\")\n",
    "print(\"  Temperature: 1 feature (unchanged)\")\n",
    "print(\"  Total: 7 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify periodicity in angle but not in temperature\n",
    "print(\"Periodicity verification:\")\n",
    "\n",
    "# Test periodicity in angle\n",
    "x_base = np.array([[0.5, 400.0], [1.0, 400.0], [2.0, 400.0]])\n",
    "x_shifted = x_base.copy()\n",
    "x_shifted[:, 0] += 2 * np.pi  # Shift angle by one period\n",
    "\n",
    "y_base = model_mixed.predict(x_base)\n",
    "y_shifted = model_mixed.predict(x_shifted)\n",
    "\n",
    "print(\"\\n1. Shifting angle by 2π (should give identical predictions):\")\n",
    "for i in range(len(x_base)):\n",
    "    print(\n",
    "        f\"   angle={x_base[i, 0]:.2f}: f={y_base[i]:.4f}, f(angle+2π)={y_shifted[i]:.4f}, diff={abs(y_base[i] - y_shifted[i]):.2e}\"\n",
    "    )\n",
    "\n",
    "# Test non-periodicity in temperature\n",
    "x_temp1 = np.array([[1.0, 300.0]])\n",
    "x_temp2 = np.array([[1.0, 500.0]])\n",
    "\n",
    "y_temp1 = model_mixed.predict(x_temp1)\n",
    "y_temp2 = model_mixed.predict(x_temp2)\n",
    "\n",
    "print(\"\\n2. Changing temperature (should give DIFFERENT predictions):\")\n",
    "print(f\"   T=300K: f={y_temp1[0]:.4f}\")\n",
    "print(f\"   T=500K: f={y_temp2[0]:.4f}\")\n",
    "print(f\"   Difference: {abs(y_temp1[0] - y_temp2[0]):.4f} (expected ~2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize partial dependencies\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Partial dependence on angle (at fixed temperature)\n",
    "angles_plot = np.linspace(0, 4 * np.pi, 200)\n",
    "X_angle = np.column_stack([angles_plot, np.full(200, 450)])\n",
    "y_angle = model_mixed.predict(X_angle)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(angles_plot, y_angle, \"b-\", linewidth=2)\n",
    "ax.axvline(2 * np.pi, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Period boundary\")\n",
    "ax.fill_between(\n",
    "    [0, 2 * np.pi],\n",
    "    ax.get_ylim()[0] - 1,\n",
    "    ax.get_ylim()[1] + 1,\n",
    "    alpha=0.1,\n",
    "    color=\"green\",\n",
    "    label=\"Training range\",\n",
    ")\n",
    "ax.set_xlabel(\"Angle (radians)\")\n",
    "ax.set_ylabel(\"Predicted property\")\n",
    "ax.set_title(\"Partial Dependence on Angle\\n(Periodic, T=450K fixed)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Partial dependence on temperature (at fixed angle)\n",
    "temps_plot = np.linspace(200, 700, 200)\n",
    "X_temp = np.column_stack([np.full(200, np.pi / 2), temps_plot])\n",
    "y_temp = model_mixed.predict(X_temp)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(temps_plot, y_temp, \"r-\", linewidth=2)\n",
    "ax.axvline(300, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axvline(600, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax.fill_between(\n",
    "    [300, 600],\n",
    "    ax.get_ylim()[0] - 1,\n",
    "    ax.get_ylim()[1] + 1,\n",
    "    alpha=0.1,\n",
    "    color=\"green\",\n",
    "    label=\"Training range\",\n",
    ")\n",
    "ax.set_xlabel(\"Temperature (K)\")\n",
    "ax.set_ylabel(\"Predicted property\")\n",
    "ax.set_title(\"Partial Dependence on Temperature\\n(Non-periodic, angle=π/2 fixed)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 4. Uncertainty Quantification with LLPR\n",
    "\n",
    "The `JAXPeriodicRegressor` includes **Last-Layer Prediction Rigidity (LLPR)** for uncertainty quantification. This provides calibrated uncertainty estimates.\n",
    "\n",
    "The uncertainty formula:\n",
    "$$\\sigma^2_* = \\alpha^2 f_*^T (F^T F + \\zeta^2 I)^{-1} f_*$$\n",
    "\n",
    "where $f_*$ is the last-layer feature vector and $F$ is the matrix of training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with uncertainty\n",
    "X_test_unc = np.linspace(0, 4 * np.pi, 100).reshape(-1, 1)\n",
    "y_pred_unc, y_std_unc = model.predict_with_uncertainty(X_test_unc)\n",
    "\n",
    "print(f\"Predictions shape: {y_pred_unc.shape}\")\n",
    "print(f\"Uncertainties shape: {y_std_unc.shape}\")\n",
    "print(f\"\\nMean uncertainty: {np.mean(y_std_unc):.4f}\")\n",
    "print(f\"Uncertainty range: [{y_std_unc.min():.4f}, {y_std_unc.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with uncertainty bands\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Training region\n",
    "plt.fill_between([0, 2 * np.pi], -2, 2, alpha=0.1, color=\"green\", label=\"Training region\")\n",
    "\n",
    "# Confidence intervals\n",
    "plt.fill_between(\n",
    "    X_test_unc.ravel(),\n",
    "    y_pred_unc - 2 * y_std_unc,\n",
    "    y_pred_unc + 2 * y_std_unc,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% confidence\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    X_test_unc.ravel(),\n",
    "    y_pred_unc - y_std_unc,\n",
    "    y_pred_unc + y_std_unc,\n",
    "    alpha=0.3,\n",
    "    color=\"blue\",\n",
    "    label=\"68% confidence\",\n",
    ")\n",
    "\n",
    "# Mean prediction\n",
    "plt.plot(X_test_unc, y_pred_unc, \"b-\", linewidth=2, label=\"Prediction\")\n",
    "\n",
    "# True function\n",
    "plt.plot(X_test_unc, np.sin(X_test_unc), \"k--\", linewidth=1.5, label=\"True: sin(x)\")\n",
    "\n",
    "# Data\n",
    "plt.scatter(X_train_range, y_train_range, alpha=0.3, c=\"gray\", s=20, label=\"Training data\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Periodic Predictions with LLPR Uncertainty\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Key observation: Uncertainty is consistent across all periods!\")\n",
    "print(\"This is because the Fourier features have the same values at equivalent phase points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare uncertainty at equivalent phase points\n",
    "x_points = np.array([[0.5], [0.5 + 2 * np.pi], [0.5 + 4 * np.pi]])\n",
    "y_pred_pts, y_std_pts = model.predict_with_uncertainty(x_points)\n",
    "\n",
    "print(\"Uncertainty at equivalent phase points:\")\n",
    "print(\"\\n  x          y_pred     std\")\n",
    "print(\"  \" + \"-\" * 30)\n",
    "for i, x in enumerate(x_points):\n",
    "    print(f\"  {x[0]:8.4f}   {y_pred_pts[i]:8.4f}   {y_std_pts[i]:.6f}\")\n",
    "\n",
    "print(\"\\nUncertainties are identical at equivalent phases (as expected)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 5. Application: Dihedral Angle Energy Surface\n",
    "\n",
    "A common application in computational chemistry: the potential energy as a function of a dihedral angle (torsion angle). This is inherently periodic with period $2\\pi$ (or sometimes $\\pi$ for symmetric molecules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dihedral angle energy data\n",
    "# This mimics a typical torsional potential (e.g., ethane rotation)\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Dihedral angles sampled sparsely\n",
    "phi = np.random.uniform(-np.pi, np.pi, n_samples)\n",
    "\n",
    "\n",
    "# Ryckaert-Bellemans type potential (common for torsions)\n",
    "# V(φ) = Σ Cn cos^n(φ)\n",
    "def torsion_potential(phi):\n",
    "    return (\n",
    "        2.0 * (1 - np.cos(phi))  # V1 term (1-fold)\n",
    "        + 1.0 * (1 - np.cos(3 * phi))  # V3 term (3-fold, common for sp3 carbons)\n",
    "        + 0.2 * (1 - np.cos(2 * phi))  # V2 term (2-fold)\n",
    "    )\n",
    "\n",
    "\n",
    "y_energy = torsion_potential(phi) + 0.1 * np.random.randn(n_samples)\n",
    "X_phi = phi.reshape(-1, 1)\n",
    "\n",
    "print(\"Dihedral angle energy surface:\")\n",
    "print(f\"  Training samples: {n_samples}\")\n",
    "print(\"  Angle range: [-π, π]\")\n",
    "print(\"  Period: 2π\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train periodic model for dihedral energy\n",
    "model_dihedral = JAXPeriodicRegressor(\n",
    "    hidden_dims=(32, 32),\n",
    "    periodicity={0: 2 * np.pi},\n",
    "    n_harmonics=5,  # Enough to capture V1, V2, V3 terms\n",
    "    epochs=500,\n",
    "    random_state=42,\n",
    ")\n",
    "model_dihedral.fit(X_phi, y_energy)\n",
    "\n",
    "print(f\"R² score: {model_dihedral.score(X_phi, y_energy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned potential energy surface\n",
    "phi_plot = np.linspace(-2 * np.pi, 2 * np.pi, 300).reshape(-1, 1)\n",
    "y_pred_dihedral, y_std_dihedral = model_dihedral.predict_with_uncertainty(phi_plot)\n",
    "y_true_dihedral = torsion_potential(phi_plot[:, 0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Energy surface\n",
    "ax = axes[0]\n",
    "ax.fill_between([-np.pi, np.pi], -0.5, 7, alpha=0.1, color=\"green\", label=\"Training range\")\n",
    "ax.fill_between(\n",
    "    phi_plot.ravel(),\n",
    "    y_pred_dihedral - 2 * y_std_dihedral,\n",
    "    y_pred_dihedral + 2 * y_std_dihedral,\n",
    "    alpha=0.2,\n",
    "    color=\"blue\",\n",
    "    label=\"95% CI\",\n",
    ")\n",
    "ax.plot(phi_plot, y_true_dihedral, \"k--\", linewidth=1.5, label=\"True potential\")\n",
    "ax.plot(phi_plot, y_pred_dihedral, \"b-\", linewidth=2, label=\"Periodic NN\")\n",
    "ax.scatter(X_phi, y_energy, alpha=0.4, c=\"gray\", s=20, label=\"Training data\")\n",
    "ax.axvline(-np.pi, color=\"gray\", linestyle=\":\", alpha=0.3)\n",
    "ax.axvline(np.pi, color=\"gray\", linestyle=\":\", alpha=0.3)\n",
    "ax.set_xlabel(\"Dihedral angle φ (radians)\")\n",
    "ax.set_ylabel(\"Energy (kcal/mol)\")\n",
    "ax.set_title(\"Dihedral Angle Potential Energy Surface\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Error and uncertainty\n",
    "ax = axes[1]\n",
    "error = np.abs(y_pred_dihedral - y_true_dihedral)\n",
    "ax.plot(phi_plot, error, \"r-\", linewidth=2, label=\"|Error|\")\n",
    "ax.plot(phi_plot, y_std_dihedral, \"b--\", linewidth=2, label=\"Predicted σ\")\n",
    "ax.fill_between(\n",
    "    [-np.pi, np.pi],\n",
    "    0,\n",
    "    ax.get_ylim()[1] if ax.get_ylim()[1] > 0 else 1,\n",
    "    alpha=0.1,\n",
    "    color=\"green\",\n",
    "    label=\"Training range\",\n",
    ")\n",
    "ax.set_xlabel(\"Dihedral angle φ (radians)\")\n",
    "ax.set_ylabel(\"Error / Uncertainty\")\n",
    "ax.set_title(\"Error vs Predicted Uncertainty\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The model perfectly captures the periodic nature of the torsional potential!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 6. Comparison: Periodic vs Non-Periodic Model\n",
    "\n",
    "Let's see what happens when we ignore the periodic nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with and without periodicity\n",
    "model_periodic = JAXPeriodicRegressor(\n",
    "    hidden_dims=(32, 32),\n",
    "    periodicity={0: 2 * np.pi},\n",
    "    n_harmonics=5,\n",
    "    epochs=500,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model_nonperiodic = JAXPeriodicRegressor(\n",
    "    hidden_dims=(32, 32),\n",
    "    periodicity=None,  # No periodicity\n",
    "    epochs=500,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train on limited range\n",
    "model_periodic.fit(X_train_range, y_train_range)\n",
    "model_nonperiodic.fit(X_train_range, y_train_range)\n",
    "\n",
    "print(\"Training on [0, 2π]:\")\n",
    "print(f\"  Periodic model R²:     {model_periodic.score(X_train_range, y_train_range):.4f}\")\n",
    "print(f\"  Non-periodic model R²: {model_nonperiodic.score(X_train_range, y_train_range):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare extrapolation\n",
    "X_extrap = np.linspace(-2 * np.pi, 4 * np.pi, 300).reshape(-1, 1)\n",
    "y_periodic = model_periodic.predict(X_extrap)\n",
    "y_nonperiodic = model_nonperiodic.predict(X_extrap)\n",
    "y_true = np.sin(X_extrap[:, 0])\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Mark regions\n",
    "plt.fill_between([0, 2 * np.pi], -3, 3, alpha=0.1, color=\"green\", label=\"Training region\")\n",
    "plt.fill_between([-2 * np.pi, 0], -3, 3, alpha=0.1, color=\"red\", label=\"Extrapolation\")\n",
    "plt.fill_between([2 * np.pi, 4 * np.pi], -3, 3, alpha=0.1, color=\"red\")\n",
    "\n",
    "plt.plot(X_extrap, y_true, \"k--\", linewidth=1.5, label=\"True: sin(x)\")\n",
    "plt.plot(X_extrap, y_periodic, \"b-\", linewidth=2, label=\"Periodic model\")\n",
    "plt.plot(X_extrap, y_nonperiodic, \"r-\", linewidth=2, label=\"Non-periodic model\")\n",
    "plt.scatter(X_train_range, y_train_range, alpha=0.3, c=\"gray\", s=20, label=\"Training data\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Periodic vs Non-Periodic Model: Extrapolation Behavior\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(-2, 2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compute extrapolation error\n",
    "extrap_mask = (X_extrap[:, 0] < 0) | (X_extrap[:, 0] > 2 * np.pi)\n",
    "rmse_periodic = np.sqrt(np.mean((y_periodic[extrap_mask] - y_true[extrap_mask]) ** 2))\n",
    "rmse_nonperiodic = np.sqrt(np.mean((y_nonperiodic[extrap_mask] - y_true[extrap_mask]) ** 2))\n",
    "\n",
    "print(\"Extrapolation RMSE:\")\n",
    "print(f\"  Periodic model:     {rmse_periodic:.4f}\")\n",
    "print(f\"  Non-periodic model: {rmse_nonperiodic:.4f}\")\n",
    "print(f\"\\nThe periodic model extrapolates {rmse_nonperiodic / rmse_periodic:.0f}x better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 7. sklearn Compatibility\n",
    "\n",
    "`JAXPeriodicRegressor` is fully compatible with sklearn's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a pipeline (note: StandardScaler only applies to non-periodic features)\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"model\",\n",
    "            JAXPeriodicRegressor(\n",
    "                hidden_dims=(16, 16),\n",
    "                epochs=100,\n",
    "                periodicity={0: 2 * np.pi},\n",
    "                n_harmonics=3,\n",
    "                standardize_X=False,  # Don't double-standardize\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(pipe, X_train_range, y_train_range, cv=3, scoring=\"r2\")\n",
    "print(f\"Cross-validation R² scores: {scores}\")\n",
    "print(f\"Mean R²: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get/set parameters\n",
    "model = JAXPeriodicRegressor(periodicity={0: 2 * np.pi}, n_harmonics=5, epochs=100)\n",
    "params = model.get_params()\n",
    "print(\"Model parameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**JAXPeriodicRegressor** provides a sklearn-compatible implementation of periodic neural networks with:\n",
    "\n",
    "### Key Features:\n",
    "- **Exact periodicity**: f(x + T) = f(x) is guaranteed by construction\n",
    "- **Fourier expansion**: Captures complex periodic patterns with harmonics\n",
    "- **Mixed features**: Some features can be periodic, others not\n",
    "- **LLPR uncertainty**: Calibrated uncertainty estimates\n",
    "- **sklearn API**: Works with pipelines, cross-validation, etc.\n",
    "\n",
    "### When to Use:\n",
    "1. **Periodic inputs**: Angles, phases, cyclic time features\n",
    "2. **Perfect extrapolation**: When you need predictions outside the training range\n",
    "3. **Physical constraints**: When periodicity is a known property\n",
    "4. **Computational chemistry**: Dihedral angles, crystallographic orientations\n",
    "\n",
    "### Parameters:\n",
    "- `periodicity`: Dict mapping feature indices to periods (e.g., {0: 2π})\n",
    "- `n_harmonics`: Number of Fourier harmonics (default: 5)\n",
    "- `hidden_dims`: Network architecture (default: (32, 32))\n",
    "- `activation`: \"silu\", \"softplus\", \"relu\", or \"tanh\" (default: silu)\n",
    "- `alpha_squared/zeta_squared`: LLPR calibration (default: 'auto')\n",
    "\n",
    "### Methods:\n",
    "- `fit(X, y)`: Train the model\n",
    "- `predict(X)`: Make predictions\n",
    "- `predict_with_uncertainty(X)`: Get (predictions, std)\n",
    "- `get_fourier_features(X)`: Inspect expanded features\n",
    "- `score(X, y)`: Compute R² score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
