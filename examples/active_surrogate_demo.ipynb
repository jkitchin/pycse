{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ActiveSurrogate: Automatic Surrogate Modeling with Active Learning\n",
    "\n",
    "This notebook demonstrates how to use the `ActiveSurrogate` class to automatically build surrogate models using active learning. The system intelligently samples an input domain to minimize expensive function evaluations while building an accurate surrogate model.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Automatic Sampling**: Starts with Latin Hypercube sampling, then uses active learning to select informative points\n",
    "- **Multiple Acquisition Functions**: Expected Improvement (EI), Upper Confidence Bound (UCB), Probability of Improvement (PI), Maximum Variance\n",
    "- **Flexible Stopping Criteria**: Mean ratio, percentile-based, absolute threshold, convergence detection\n",
    "- **Batch Support**: Can sample multiple points per iteration for parallel evaluation\n",
    "- **History Tracking**: Records all metrics for analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "from pycse.pyroxy import ActiveSurrogate\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Usage with a 1D Function\n",
    "\n",
    "Let's start with a simple 1D function that has some interesting features (multiple local minima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a moderately complex test function\n",
    "def expensive_function(X):\n",
    "    \"\"\"A function with multiple local minima.\"\"\"\n",
    "    x = X.flatten()\n",
    "    return np.sin(x) + 0.5 * np.sin(3 * x) + 0.1 * x\n",
    "\n",
    "# Define the domain\n",
    "bounds = [(0, 10)]\n",
    "\n",
    "# Create a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "\n",
    "# Build the surrogate with active learning\n",
    "print(\"Building surrogate with Expected Improvement acquisition...\")\n",
    "surrogate, history = ActiveSurrogate.build(\n",
    "    func=expensive_function,\n",
    "    bounds=bounds,\n",
    "    model=model,\n",
    "    acquisition='ei',\n",
    "    stopping_criterion='mean_ratio',\n",
    "    stopping_threshold=1.5,\n",
    "    n_initial=5,\n",
    "    max_iterations=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal surrogate built with {len(surrogate.xtrain)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test points\n",
    "X_plot = np.linspace(0, 10, 200).reshape(-1, 1)\n",
    "y_true = expensive_function(X_plot)\n",
    "y_pred = surrogate(X_plot)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Left: Surrogate vs True Function\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(X_plot, y_true, 'b-', label='True function', linewidth=2)\n",
    "plt.plot(X_plot, y_pred, 'r--', label='Surrogate', linewidth=2)\n",
    "plt.scatter(surrogate.xtrain, surrogate.ytrain, c='black', s=50,\n",
    "            label=f'Samples (n={len(surrogate.xtrain)})', zorder=5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Surrogate vs True Function')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Sample locations over iterations\n",
    "plt.subplot(1, 2, 2)\n",
    "# Mark initial samples\n",
    "plt.scatter(surrogate.xtrain[:5], surrogate.ytrain[:5], \n",
    "            c='green', s=100, marker='s', label='Initial (LHS)', zorder=5)\n",
    "# Mark actively selected samples\n",
    "if len(surrogate.xtrain) > 5:\n",
    "    plt.scatter(surrogate.xtrain[5:], surrogate.ytrain[5:], \n",
    "                c='red', s=100, marker='^', label='Active learning', zorder=5)\n",
    "plt.plot(X_plot, y_true, 'b-', alpha=0.3, linewidth=1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Sample Selection Strategy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy metrics\n",
    "rmse = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "print(f\"\\nSurrogate Accuracy:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  Max Error: {np.max(np.abs(y_pred - y_true)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Sample progression\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['iterations'], history['n_samples'], 'b-o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Samples')\n",
    "plt.title('Sample Count Progression')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Uncertainty evolution\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['iterations'], history['mean_uncertainty'], 'g-o', label='Mean')\n",
    "plt.plot(history['iterations'], history['max_uncertainty'], 'r-s', label='Max')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Uncertainty')\n",
    "plt.legend()\n",
    "plt.title('Uncertainty Evolution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Acquisition values\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['iterations'], history['acquisition_values'], 'm-o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Acquisition Value')\n",
    "plt.title('Acquisition Value Trends')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Comparing Different Acquisition Functions\n",
    "\n",
    "Different acquisition functions have different exploration/exploitation trade-offs. Let's compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_functions = ['ei', 'ucb', 'pi', 'variance']\n",
    "acquisition_names = {\n",
    "    'ei': 'Expected Improvement',\n",
    "    'ucb': 'Upper Confidence Bound',\n",
    "    'pi': 'Probability of Improvement',\n",
    "    'variance': 'Maximum Variance'\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for acq in acquisition_functions:\n",
    "    print(f\"\\nTesting {acquisition_names[acq]}...\")\n",
    "    \n",
    "    # Create fresh model for each test\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "    \n",
    "    # Build surrogate\n",
    "    surrogate, history = ActiveSurrogate.build(\n",
    "        func=expensive_function,\n",
    "        bounds=bounds,\n",
    "        model=model,\n",
    "        acquisition=acq,\n",
    "        stopping_criterion='absolute',\n",
    "        stopping_threshold=0.15,\n",
    "        n_initial=5,\n",
    "        max_iterations=15,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    y_pred = surrogate(X_plot)\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "    \n",
    "    results[acq] = {\n",
    "        'surrogate': surrogate,\n",
    "        'history': history,\n",
    "        'y_pred': y_pred,\n",
    "        'rmse': rmse,\n",
    "        'n_samples': len(surrogate.xtrain)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Samples used: {results[acq]['n_samples']}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, acq in enumerate(acquisition_functions):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot true function and surrogate\n",
    "    ax.plot(X_plot, y_true, 'b-', label='True', linewidth=2, alpha=0.5)\n",
    "    ax.plot(X_plot, results[acq]['y_pred'], 'r--', label='Surrogate', linewidth=2)\n",
    "    \n",
    "    # Plot sample points\n",
    "    surrogate = results[acq]['surrogate']\n",
    "    ax.scatter(surrogate.xtrain, surrogate.ytrain, c='black', s=50, zorder=5)\n",
    "    \n",
    "    ax.set_title(f\"{acquisition_names[acq]}\\n\"\n",
    "                 f\"Samples: {results[acq]['n_samples']}, RMSE: {results[acq]['rmse']:.4f}\")\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\nSummary Comparison:\")\n",
    "print(f\"{'Acquisition':<25} {'Samples':<10} {'RMSE':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for acq in acquisition_functions:\n",
    "    print(f\"{acquisition_names[acq]:<25} {results[acq]['n_samples']:<10} {results[acq]['rmse']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: 2D Function with Visualization\n",
    "\n",
    "Let's demonstrate active learning on a 2D function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D test function\n",
    "def func_2d(X):\n",
    "    \"\"\"2D test function with interesting features.\"\"\"\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    return np.sin(x1) * np.cos(x2) + 0.1 * x1\n",
    "\n",
    "# Define 2D domain\n",
    "bounds_2d = [(0, 2*np.pi), (0, 2*np.pi)]\n",
    "\n",
    "# Create model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF([1.0, 1.0], (1e-2, 1e2))\n",
    "model_2d = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "\n",
    "# Build surrogate\n",
    "print(\"Building 2D surrogate...\")\n",
    "surrogate_2d, history_2d = ActiveSurrogate.build(\n",
    "    func=func_2d,\n",
    "    bounds=bounds_2d,\n",
    "    model=model_2d,\n",
    "    acquisition='ei',\n",
    "    stopping_criterion='mean_ratio',\n",
    "    stopping_threshold=2.0,\n",
    "    n_initial=10,\n",
    "    max_iterations=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n2D Surrogate built with {len(surrogate_2d.xtrain)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid for visualization\n",
    "x1_grid = np.linspace(0, 2*np.pi, 50)\n",
    "x2_grid = np.linspace(0, 2*np.pi, 50)\n",
    "X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "# Evaluate true function and surrogate\n",
    "y_true_2d = func_2d(X_grid).reshape(X1.shape)\n",
    "y_pred_2d = surrogate_2d(X_grid).reshape(X1.shape)\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "\n",
    "# True function\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X1, X2, y_true_2d, cmap='viridis', alpha=0.8)\n",
    "ax1.scatter(surrogate_2d.xtrain[:, 0], surrogate_2d.xtrain[:, 1], \n",
    "            surrogate_2d.ytrain, c='red', s=50, marker='o')\n",
    "ax1.set_title('True Function + Sample Points')\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.set_zlabel('y')\n",
    "\n",
    "# Surrogate\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X1, X2, y_pred_2d, cmap='viridis', alpha=0.8)\n",
    "ax2.scatter(surrogate_2d.xtrain[:, 0], surrogate_2d.xtrain[:, 1], \n",
    "            surrogate_2d.ytrain, c='red', s=50, marker='o')\n",
    "ax2.set_title('Surrogate Model')\n",
    "ax2.set_xlabel('x1')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y')\n",
    "\n",
    "# Error\n",
    "ax3 = fig.add_subplot(133)\n",
    "error = np.abs(y_true_2d - y_pred_2d)\n",
    "contour = ax3.contourf(X1, X2, error, levels=20, cmap='Reds')\n",
    "ax3.scatter(surrogate_2d.xtrain[:, 0], surrogate_2d.xtrain[:, 1], \n",
    "            c='blue', s=50, marker='o', edgecolors='white', linewidths=1.5)\n",
    "plt.colorbar(contour, ax=ax3, label='Absolute Error')\n",
    "ax3.set_title('Prediction Error')\n",
    "ax3.set_xlabel('x1')\n",
    "ax3.set_ylabel('x2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n2D Surrogate Statistics:\")\n",
    "print(f\"  Mean Absolute Error: {np.mean(error):.4f}\")\n",
    "print(f\"  Max Absolute Error: {np.max(error):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(np.mean(error**2)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using Batch Mode for Parallel Evaluation\n",
    "\n",
    "When your function can be evaluated in parallel, batch mode samples multiple points per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build surrogate with batch sampling\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "model_batch = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "\n",
    "print(\"Building surrogate with batch_size=3...\")\n",
    "surrogate_batch, history_batch = ActiveSurrogate.build(\n",
    "    func=expensive_function,\n",
    "    bounds=bounds,\n",
    "    model=model_batch,\n",
    "    acquisition='ucb',\n",
    "    batch_size=3,  # Sample 3 points per iteration\n",
    "    stopping_criterion='absolute',\n",
    "    stopping_threshold=0.15,\n",
    "    n_initial=5,\n",
    "    max_iterations=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch surrogate built with {len(surrogate_batch.xtrain)} samples\")\n",
    "print(f\"Iterations run: {len(history_batch['iterations'])}\")\n",
    "print(f\"Average samples per iteration: {(len(surrogate_batch.xtrain) - 5) / len(history_batch['iterations']):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Custom Callback for Monitoring\n",
    "\n",
    "You can provide a callback function to monitor or log the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom callback\n",
    "callback_data = {'iterations': [], 'uncertainties': []}\n",
    "\n",
    "def my_callback(iteration, history):\n",
    "    \"\"\"Custom callback to track specific metrics.\"\"\"\n",
    "    callback_data['iterations'].append(iteration)\n",
    "    callback_data['uncertainties'].append(history['mean_uncertainty'][-1])\n",
    "    \n",
    "    if iteration % 5 == 0:\n",
    "        print(f\"  [Callback] Iteration {iteration}: Mean uncertainty = {history['mean_uncertainty'][-1]:.4f}\")\n",
    "\n",
    "# Build surrogate with callback\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "model_cb = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "\n",
    "print(\"Building surrogate with custom callback...\")\n",
    "surrogate_cb, history_cb = ActiveSurrogate.build(\n",
    "    func=expensive_function,\n",
    "    bounds=bounds,\n",
    "    model=model_cb,\n",
    "    acquisition='ei',\n",
    "    stopping_criterion='convergence',\n",
    "    stopping_threshold=0.05,\n",
    "    n_initial=5,\n",
    "    max_iterations=25,\n",
    "    callback=my_callback,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\nCallback tracked {len(callback_data['iterations'])} iterations\")\n",
    "\n",
    "# Plot callback data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(callback_data['iterations'], callback_data['uncertainties'], 'b-o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Mean Uncertainty')\n",
    "plt.title('Custom Callback Monitoring')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic Usage**: Building a surrogate with default settings\n",
    "2. **Acquisition Functions**: Comparing EI, UCB, PI, and variance-based strategies\n",
    "3. **2D Functions**: Extending to multi-dimensional problems\n",
    "4. **Batch Mode**: Sampling multiple points per iteration for parallel evaluation\n",
    "5. **Custom Callbacks**: Monitoring and logging during training\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Expected Improvement (EI)** balances exploration and exploitation well for optimization\n",
    "- **Maximum Variance** is best for pure space-filling and coverage\n",
    "- **Batch mode** with hallucination provides diverse samples for parallel evaluation\n",
    "- **Stopping criteria** can be tuned based on your accuracy requirements\n",
    "- The returned surrogate is a standard `_Surrogate` object that can be used like any other pyroxy surrogate\n",
    "\n",
    "### When to Use ActiveSurrogate\n",
    "\n",
    "- Your function is expensive to evaluate (simulations, experiments, etc.)\n",
    "- You want to minimize the number of function evaluations\n",
    "- You need a surrogate model for optimization or analysis\n",
    "- You want automatic, intelligent sampling rather than manual grid selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
