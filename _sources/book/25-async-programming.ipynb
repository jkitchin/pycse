{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Asynchronous Programming in Python\n",
    "\n",
    "- KEYWORDS: asyncio, async, await, concurrency, aiohttp, event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Introduction: Async vs Parallel\n",
    "\n",
    "In the [previous chapter on parallel processing](24-parallel-processing.ipynb), we learned how to use multiple CPU cores to speed up computation. This chapter covers a complementary technique: **asynchronous programming**.\n",
    "\n",
    "| Parallel Processing | Async Programming |\n",
    "|---------------------|-------------------|\n",
    "| Multiple workers doing tasks simultaneously | One worker switching between tasks |\n",
    "| Best for CPU-bound work | Best for I/O-bound work |\n",
    "| Uses multiple cores | Uses one core efficiently |\n",
    "| `multiprocessing`, `joblib` | `asyncio`, `aiohttp` |\n",
    "\n",
    "**The key insight**: When your program spends most of its time *waiting* (for network responses, file I/O, instrument readings), async lets you do useful work during that wait time—all in a single thread.\n",
    "\n",
    "### When to Use Async\n",
    "\n",
    "Async programming shines when:\n",
    "- Fetching data from multiple web APIs\n",
    "- Polling multiple sensors or instruments\n",
    "- Handling many concurrent network connections\n",
    "- Reading/writing many files\n",
    "\n",
    "Async does NOT help when:\n",
    "- Doing heavy numerical computation (use multiprocessing)\n",
    "- Tasks are CPU-bound rather than I/O-bound\n",
    "- You only have one or two sequential I/O operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Note: In Jupyter notebooks, there's already an event loop running.\n",
    "# We use 'await' directly instead of 'asyncio.run()'\n",
    "# In regular Python scripts, you would use: asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## The Event Loop Mental Model\n",
    "\n",
    "Think of async programming like a chef in a kitchen:\n",
    "\n",
    "- **Synchronous**: Cook one dish completely, then start the next. While water boils, stand there waiting.\n",
    "- **Asynchronous**: Start boiling water, then chop vegetables while waiting. When water boils, come back to it.\n",
    "\n",
    "The **event loop** is like the chef's brain—it keeps track of all the tasks and switches between them when one is waiting.\n",
    "\n",
    "```\n",
    "Event Loop:\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Task A: [run]──[wait for I/O]──────────────────[run]──done │\n",
    "│  Task B:       [run]──[wait]────────[run]──done             │\n",
    "│  Task C:              [run]──[wait]───────────[run]──done   │\n",
    "│          ─────────────────────────────────────────────────► │\n",
    "│                              time                           │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "While Task A waits for I/O, Tasks B and C can run. Total time is much less than running sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "## Basic async/await Syntax\n",
    "\n",
    "Python's async programming uses two keywords:\n",
    "- `async def`: Defines a *coroutine* (an async function)\n",
    "- `await`: Pauses execution until the awaited coroutine completes\n",
    "\n",
    "Let's start with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def say_hello(name, delay):\n",
    "    \"\"\"A simple coroutine that waits, then greets.\"\"\"\n",
    "    await asyncio.sleep(delay)  # Non-blocking sleep\n",
    "    print(f\"Hello, {name}! (after {delay}s)\")\n",
    "    return f\"Greeted {name}\"\n",
    "\n",
    "# Run a single coroutine\n",
    "result = await say_hello(\"World\", 1)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "**Important**: `asyncio.sleep()` is different from `time.sleep()`:\n",
    "- `time.sleep()` blocks the entire thread—nothing else can run\n",
    "- `asyncio.sleep()` yields control to the event loop—other tasks can run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "### Sequential vs Concurrent Execution\n",
    "\n",
    "The power of async comes from running multiple coroutines *concurrently*. Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simulate_sensor_read(sensor_id, read_time):\n",
    "    \"\"\"Simulate reading from a sensor (I/O-bound operation).\"\"\"\n",
    "    await asyncio.sleep(read_time)  # Simulate I/O delay\n",
    "    value = np.random.normal(100, 5)  # Simulated reading\n",
    "    return sensor_id, value\n",
    "\n",
    "sensors = [(\"temp_1\", 0.5), (\"temp_2\", 0.7), (\"pressure\", 0.4), (\"flow\", 0.6)]\n",
    "\n",
    "# SEQUENTIAL: One at a time\n",
    "start = time.perf_counter()\n",
    "sequential_results = []\n",
    "for sensor_id, read_time in sensors:\n",
    "    result = await simulate_sensor_read(sensor_id, read_time)\n",
    "    sequential_results.append(result)\n",
    "sequential_time = time.perf_counter() - start\n",
    "print(f\"Sequential: {sequential_time:.2f}s\")\n",
    "\n",
    "# CONCURRENT: All at once with asyncio.gather()\n",
    "start = time.perf_counter()\n",
    "tasks = [simulate_sensor_read(sid, rt) for sid, rt in sensors]\n",
    "concurrent_results = await asyncio.gather(*tasks)\n",
    "concurrent_time = time.perf_counter() - start\n",
    "print(f\"Concurrent: {concurrent_time:.2f}s\")\n",
    "print(f\"Speedup: {sequential_time / concurrent_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "The concurrent version takes only as long as the *slowest* task, not the sum of all tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Core asyncio Patterns\n",
    "\n",
    "### Pattern 1: `asyncio.gather()` - Run Multiple Coroutines\n",
    "\n",
    "The most common pattern. Run multiple coroutines and get all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_temperature(location):\n",
    "    \"\"\"Simulate fetching temperature from a weather API.\"\"\"\n",
    "    await asyncio.sleep(np.random.uniform(0.3, 0.8))\n",
    "    temp = np.random.uniform(15, 35)\n",
    "    return {\"location\": location, \"temp_C\": temp}\n",
    "\n",
    "locations = [\"Pittsburgh\", \"New York\", \"Chicago\", \"Los Angeles\", \"Houston\"]\n",
    "\n",
    "# Gather all results\n",
    "results = await asyncio.gather(*[fetch_temperature(loc) for loc in locations])\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['location']}: {r['temp_C']:.1f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "### Pattern 2: `asyncio.create_task()` - Fire and Forget (or Join Later)\n",
    "\n",
    "Create a task that runs in the background. You can await it later or let it run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def background_logger(interval, count):\n",
    "    \"\"\"Log messages at regular intervals.\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(interval)\n",
    "        print(f\"  [Log {i+1}/{count}] Background task running...\")\n",
    "    return \"Logging complete\"\n",
    "\n",
    "async def main_work():\n",
    "    \"\"\"Do some main work while background task runs.\"\"\"\n",
    "    print(\"Starting main work...\")\n",
    "    await asyncio.sleep(1.5)\n",
    "    print(\"Main work complete!\")\n",
    "    return \"Main result\"\n",
    "\n",
    "# Create background task\n",
    "logger_task = asyncio.create_task(background_logger(0.4, 5))\n",
    "\n",
    "# Do main work while logger runs\n",
    "main_result = await main_work()\n",
    "\n",
    "# Wait for background task to finish\n",
    "logger_result = await logger_task\n",
    "print(f\"\\nResults: {main_result}, {logger_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "### Pattern 3: `asyncio.as_completed()` - Process Results as They Arrive\n",
    "\n",
    "When you want to process results as soon as they're ready, not wait for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def slow_computation(task_id, duration):\n",
    "    \"\"\"A task that takes variable time.\"\"\"\n",
    "    await asyncio.sleep(duration)\n",
    "    return task_id, duration\n",
    "\n",
    "# Tasks with different durations\n",
    "task_specs = [(\"A\", 0.8), (\"B\", 0.3), (\"C\", 0.5), (\"D\", 0.2)]\n",
    "tasks = [slow_computation(tid, dur) for tid, dur in task_specs]\n",
    "\n",
    "print(\"Processing results as they complete:\")\n",
    "for coro in asyncio.as_completed(tasks):\n",
    "    task_id, duration = await coro\n",
    "    print(f\"  Task {task_id} finished (took {duration}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "Notice the order: D, B, C, A—shortest tasks finish first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "### Pattern 4: Timeouts with `asyncio.wait_for()`\n",
    "\n",
    "In real systems, you need to handle slow or hanging operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def unreliable_sensor(sensor_id):\n",
    "    \"\"\"A sensor that sometimes takes too long.\"\"\"\n",
    "    delay = np.random.uniform(0.1, 2.0)\n",
    "    await asyncio.sleep(delay)\n",
    "    return sensor_id, np.random.normal(25, 2)\n",
    "\n",
    "async def read_with_timeout(sensor_id, timeout=0.5):\n",
    "    \"\"\"Read sensor with timeout protection.\"\"\"\n",
    "    try:\n",
    "        result = await asyncio.wait_for(\n",
    "            unreliable_sensor(sensor_id), \n",
    "            timeout=timeout\n",
    "        )\n",
    "        return {\"sensor\": sensor_id, \"status\": \"ok\", \"value\": result[1]}\n",
    "    except asyncio.TimeoutError:\n",
    "        return {\"sensor\": sensor_id, \"status\": \"timeout\", \"value\": None}\n",
    "\n",
    "# Read from 8 sensors with timeout\n",
    "sensor_ids = [f\"sensor_{i}\" for i in range(8)]\n",
    "results = await asyncio.gather(*[read_with_timeout(sid) for sid in sensor_ids])\n",
    "\n",
    "ok_count = sum(1 for r in results if r[\"status\"] == \"ok\")\n",
    "print(f\"Successful reads: {ok_count}/{len(results)}\")\n",
    "for r in results:\n",
    "    status = f\"{r['value']:.2f}\" if r['value'] else \"TIMEOUT\"\n",
    "    print(f\"  {r['sensor']}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3",
   "metadata": {},
   "source": [
    "### Pattern 5: Semaphores for Rate Limiting\n",
    "\n",
    "When calling external APIs, you often need to limit concurrent requests to avoid overwhelming the server or hitting rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rate_limited_request(url, semaphore):\n",
    "    \"\"\"Make a request, but limit concurrency.\"\"\"\n",
    "    async with semaphore:  # Only N tasks can hold the semaphore at once\n",
    "        print(f\"  Starting request to {url}\")\n",
    "        await asyncio.sleep(0.5)  # Simulate request\n",
    "        print(f\"  Completed request to {url}\")\n",
    "        return f\"Data from {url}\"\n",
    "\n",
    "# Limit to 3 concurrent requests\n",
    "semaphore = asyncio.Semaphore(3)\n",
    "urls = [f\"api/endpoint/{i}\" for i in range(6)]\n",
    "\n",
    "print(\"Making 6 requests with max 3 concurrent:\")\n",
    "start = time.perf_counter()\n",
    "results = await asyncio.gather(*[rate_limited_request(url, semaphore) for url in urls])\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"\\nTotal time: {elapsed:.2f}s (2 batches of 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## Engineering Example: Fetching Chemical Data from PubChem\n",
    "\n",
    "Let's use async to fetch molecular properties for multiple compounds from the [PubChem API](https://pubchem.ncbi.nlm.nih.gov/). This is a real-world example of concurrent API requests.\n",
    "\n",
    "We'll use Python's built-in `urllib` for simplicity, wrapped in async. For production code, consider using `aiohttp` or `httpx` (discussed later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "def fetch_pubchem_sync(compound_name):\n",
    "    \"\"\"Synchronous fetch of compound data from PubChem.\"\"\"\n",
    "    base_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n",
    "    url = f\"{base_url}/compound/name/{compound_name}/property/MolecularWeight,MolecularFormula,IUPACName/JSON\"\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(url, timeout=10) as response:\n",
    "            data = json.loads(response.read().decode())\n",
    "            props = data[\"PropertyTable\"][\"Properties\"][0]\n",
    "            return {\n",
    "                \"name\": compound_name,\n",
    "                \"formula\": props.get(\"MolecularFormula\", \"N/A\"),\n",
    "                \"mw\": props.get(\"MolecularWeight\", \"N/A\"),\n",
    "                \"iupac\": props.get(\"IUPACName\", \"N/A\"),\n",
    "                \"status\": \"ok\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"name\": compound_name, \"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "# Test with one compound\n",
    "result = fetch_pubchem_sync(\"ethanol\")\n",
    "print(f\"Ethanol: {result['formula']}, MW = {result['mw']} g/mol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of compounds to look up\n",
    "compounds = [\n",
    "    \"water\", \"ethanol\", \"methanol\", \"acetone\", \"benzene\",\n",
    "    \"toluene\", \"hexane\", \"acetic acid\", \"ammonia\", \"glucose\"\n",
    "]\n",
    "\n",
    "# SEQUENTIAL: Fetch one at a time\n",
    "print(\"Sequential fetch:\")\n",
    "start = time.perf_counter()\n",
    "sequential_results = [fetch_pubchem_sync(c) for c in compounds]\n",
    "sequential_time = time.perf_counter() - start\n",
    "print(f\"  Time: {sequential_time:.2f}s for {len(compounds)} compounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_pubchem_async(compound_name, semaphore):\n",
    "    \"\"\"Async fetch using run_in_executor for the blocking HTTP call.\"\"\"\n",
    "    async with semaphore:  # Rate limit to be nice to PubChem\n",
    "        loop = asyncio.get_event_loop()\n",
    "        # Run the synchronous function in a thread pool\n",
    "        result = await loop.run_in_executor(None, fetch_pubchem_sync, compound_name)\n",
    "        return result\n",
    "\n",
    "# CONCURRENT: Fetch all at once (with rate limiting)\n",
    "print(\"Concurrent fetch (max 5 simultaneous):\")\n",
    "semaphore = asyncio.Semaphore(5)  # Limit concurrent requests\n",
    "\n",
    "start = time.perf_counter()\n",
    "concurrent_results = await asyncio.gather(\n",
    "    *[fetch_pubchem_async(c, semaphore) for c in compounds]\n",
    ")\n",
    "concurrent_time = time.perf_counter() - start\n",
    "print(f\"  Time: {concurrent_time:.2f}s for {len(compounds)} compounds\")\n",
    "print(f\"  Speedup: {sequential_time / concurrent_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in a nice table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'Compound':<15} {'Formula':<15} {'MW (g/mol)':<12} {'Status'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for r in concurrent_results:\n",
    "    if r[\"status\"] == \"ok\":\n",
    "        print(f\"{r['name']:<15} {r['formula']:<15} {r['mw']:<12} OK\")\n",
    "    else:\n",
    "        print(f\"{r['name']:<15} {'--':<15} {'--':<12} {r['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0",
   "metadata": {},
   "source": [
    "## Async Context Managers and Iterators\n",
    "\n",
    "Python supports async versions of context managers (`async with`) and iterators (`async for`).\n",
    "\n",
    "### Async Context Managers\n",
    "\n",
    "Useful for resources that need async setup/teardown (database connections, HTTP sessions, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncInstrumentConnection:\n",
    "    \"\"\"Simulate an async connection to a lab instrument.\"\"\"\n",
    "    \n",
    "    def __init__(self, instrument_id):\n",
    "        self.instrument_id = instrument_id\n",
    "        self.connected = False\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Async context manager entry.\"\"\"\n",
    "        print(f\"Connecting to {self.instrument_id}...\")\n",
    "        await asyncio.sleep(0.3)  # Simulate connection time\n",
    "        self.connected = True\n",
    "        print(f\"Connected to {self.instrument_id}\")\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Async context manager exit.\"\"\"\n",
    "        print(f\"Disconnecting from {self.instrument_id}...\")\n",
    "        await asyncio.sleep(0.1)  # Simulate disconnect\n",
    "        self.connected = False\n",
    "        print(f\"Disconnected from {self.instrument_id}\")\n",
    "    \n",
    "    async def read_value(self):\n",
    "        \"\"\"Read a value from the instrument.\"\"\"\n",
    "        if not self.connected:\n",
    "            raise RuntimeError(\"Not connected!\")\n",
    "        await asyncio.sleep(0.2)  # Simulate read time\n",
    "        return np.random.normal(100, 2)\n",
    "\n",
    "# Use the async context manager\n",
    "async with AsyncInstrumentConnection(\"Spectrometer-01\") as instrument:\n",
    "    readings = []\n",
    "    for i in range(3):\n",
    "        value = await instrument.read_value()\n",
    "        readings.append(value)\n",
    "        print(f\"  Reading {i+1}: {value:.2f}\")\n",
    "    print(f\"Average: {np.mean(readings):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0a1b2",
   "metadata": {},
   "source": [
    "### Async Iterators\n",
    "\n",
    "Perfect for streaming data from instruments or APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncSensorStream:\n",
    "    \"\"\"Stream readings from a sensor asynchronously.\"\"\"\n",
    "    \n",
    "    def __init__(self, sensor_id, n_readings, interval=0.2):\n",
    "        self.sensor_id = sensor_id\n",
    "        self.n_readings = n_readings\n",
    "        self.interval = interval\n",
    "        self.current = 0\n",
    "    \n",
    "    def __aiter__(self):\n",
    "        return self\n",
    "    \n",
    "    async def __anext__(self):\n",
    "        if self.current >= self.n_readings:\n",
    "            raise StopAsyncIteration\n",
    "        \n",
    "        await asyncio.sleep(self.interval)  # Wait for next reading\n",
    "        self.current += 1\n",
    "        \n",
    "        # Simulate a sensor with drift and noise\n",
    "        base_value = 25 + 0.1 * self.current  # Slight drift\n",
    "        noise = np.random.normal(0, 0.5)\n",
    "        return {\n",
    "            \"sensor\": self.sensor_id,\n",
    "            \"reading\": self.current,\n",
    "            \"value\": base_value + noise,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "\n",
    "# Stream data from the sensor\n",
    "print(\"Streaming sensor data:\")\n",
    "readings = []\n",
    "async for data in AsyncSensorStream(\"TempSensor\", n_readings=5):\n",
    "    print(f\"  [{data['reading']}] {data['value']:.2f}°C\")\n",
    "    readings.append(data['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4e5",
   "metadata": {},
   "source": [
    "## Engineering Example: Concurrent Sensor Monitoring\n",
    "\n",
    "Let's build a realistic example: monitoring multiple process variables (temperature, pressure, flow rate) from different sensors simultaneously, with data logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessSensor:\n",
    "    \"\"\"Simulate a process sensor with realistic behavior.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, units, setpoint, noise_std, read_time):\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.setpoint = setpoint\n",
    "        self.noise_std = noise_std\n",
    "        self.read_time = read_time  # Time to get a reading\n",
    "        self.value = setpoint\n",
    "    \n",
    "    async def read(self):\n",
    "        \"\"\"Read current value (async with simulated I/O delay).\"\"\"\n",
    "        await asyncio.sleep(self.read_time)\n",
    "        # Simulate process dynamics: random walk around setpoint\n",
    "        self.value += np.random.normal(0, self.noise_std)\n",
    "        # Mean reversion toward setpoint\n",
    "        self.value += 0.1 * (self.setpoint - self.value)\n",
    "        return {\n",
    "            \"sensor\": self.name,\n",
    "            \"value\": self.value,\n",
    "            \"units\": self.units,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "\n",
    "# Create sensors for a chemical process\n",
    "sensors = [\n",
    "    ProcessSensor(\"Reactor_Temp\", \"°C\", setpoint=150, noise_std=2, read_time=0.3),\n",
    "    ProcessSensor(\"Reactor_Press\", \"bar\", setpoint=5, noise_std=0.1, read_time=0.2),\n",
    "    ProcessSensor(\"Feed_Flow\", \"L/min\", setpoint=10, noise_std=0.5, read_time=0.25),\n",
    "    ProcessSensor(\"Coolant_Temp\", \"°C\", setpoint=25, noise_std=1, read_time=0.15),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitor_process(sensors, duration=3, poll_interval=0.5):\n",
    "    \"\"\"Monitor all sensors concurrently for a specified duration.\"\"\"\n",
    "    start_time = time.time()\n",
    "    all_data = {s.name: [] for s in sensors}\n",
    "    \n",
    "    while time.time() - start_time < duration:\n",
    "        # Read all sensors concurrently\n",
    "        readings = await asyncio.gather(*[s.read() for s in sensors])\n",
    "        \n",
    "        # Log the readings\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nt = {elapsed:.1f}s:\")\n",
    "        for reading in readings:\n",
    "            print(f\"  {reading['sensor']}: {reading['value']:.2f} {reading['units']}\")\n",
    "            all_data[reading['sensor']].append({\n",
    "                'time': elapsed,\n",
    "                'value': reading['value']\n",
    "            })\n",
    "        \n",
    "        # Wait before next poll\n",
    "        await asyncio.sleep(poll_interval)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "print(\"Starting process monitoring...\")\n",
    "monitoring_data = await monitor_process(sensors, duration=3, poll_interval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the monitoring data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (sensor_name, data) in zip(axes, monitoring_data.items()):\n",
    "    times = [d['time'] for d in data]\n",
    "    values = [d['value'] for d in data]\n",
    "    \n",
    "    ax.plot(times, values, 'b-o', markersize=6)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel(sensor_name.replace('_', ' '))\n",
    "    ax.set_title(sensor_name.replace('_', ' '))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Concurrent Process Monitoring', y=1.02, fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8c9",
   "metadata": {},
   "source": [
    "## External Libraries for Async I/O\n",
    "\n",
    "While we've used `asyncio` with thread executors for HTTP requests, there are dedicated async libraries that are more efficient:\n",
    "\n",
    "### aiohttp\n",
    "\n",
    "[aiohttp](https://docs.aiohttp.org/) is the most popular async HTTP client/server library.\n",
    "\n",
    "```python\n",
    "import aiohttp\n",
    "\n",
    "async def fetch_with_aiohttp(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.json()\n",
    "\n",
    "# Fetch multiple URLs concurrently\n",
    "async def fetch_all(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [session.get(url) for url in urls]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        return [await r.json() for r in responses]\n",
    "```\n",
    "\n",
    "### httpx\n",
    "\n",
    "[httpx](https://www.python-httpx.org/) provides a requests-like API with async support.\n",
    "\n",
    "```python\n",
    "import httpx\n",
    "\n",
    "async def fetch_with_httpx(url):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url)\n",
    "        return response.json()\n",
    "```\n",
    "\n",
    "### aiofiles\n",
    "\n",
    "[aiofiles](https://github.com/Tinche/aiofiles) provides async file operations.\n",
    "\n",
    "```python\n",
    "import aiofiles\n",
    "\n",
    "async def read_file_async(filepath):\n",
    "    async with aiofiles.open(filepath, mode='r') as f:\n",
    "        contents = await f.read()\n",
    "    return contents\n",
    "\n",
    "async def write_file_async(filepath, data):\n",
    "    async with aiofiles.open(filepath, mode='w') as f:\n",
    "        await f.write(data)\n",
    "```\n",
    "\n",
    "These libraries are truly non-blocking (unlike our executor-based approach) and are more efficient for high-concurrency applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9d0",
   "metadata": {},
   "source": [
    "## Combining Async with Parallel Processing\n",
    "\n",
    "Sometimes you need both: async for I/O and parallel for CPU. The pattern is:\n",
    "1. Use async to gather data concurrently\n",
    "2. Use multiprocessing to process the data in parallel\n",
    "\n",
    "### `asyncio.to_thread()` for Blocking Operations\n",
    "\n",
    "Python 3.9+ provides `asyncio.to_thread()` to run blocking code in a thread pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "def solve_ode_blocking(k):\n",
    "    \"\"\"CPU-bound: Solve an ODE (blocking operation).\"\"\"\n",
    "    def ode(t, C):\n",
    "        return -k * C\n",
    "    sol = solve_ivp(ode, [0, 10], [1.0], dense_output=True)\n",
    "    return k, sol.y[0, -1]\n",
    "\n",
    "async def fetch_and_compute(k):\n",
    "    \"\"\"Async wrapper that runs CPU-bound work in a thread.\"\"\"\n",
    "    # Simulate fetching the rate constant from an API\n",
    "    await asyncio.sleep(0.1)  # I/O wait\n",
    "    \n",
    "    # Run CPU-bound computation in thread pool\n",
    "    result = await asyncio.to_thread(solve_ode_blocking, k)\n",
    "    return result\n",
    "\n",
    "# Process multiple rate constants\n",
    "k_values = np.linspace(0.1, 2.0, 10)\n",
    "\n",
    "start = time.perf_counter()\n",
    "results = await asyncio.gather(*[fetch_and_compute(k) for k in k_values])\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"Completed {len(results)} computations in {elapsed:.2f}s\")\n",
    "for k, final_conc in results[:3]:\n",
    "    print(f\"  k={k:.2f}: C_final={final_conc:.4f}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1f2",
   "metadata": {},
   "source": [
    "### Full Pattern: Async Fetch + Parallel Process\n",
    "\n",
    "For heavy CPU work, combine async with `ProcessPoolExecutor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "async def fetch_parameters():\n",
    "    \"\"\"Async: Fetch parameters from multiple sources.\"\"\"\n",
    "    async def fetch_one(source_id):\n",
    "        await asyncio.sleep(np.random.uniform(0.1, 0.3))  # Simulate API call\n",
    "        return {\"source\": source_id, \"k\": np.random.uniform(0.1, 2.0)}\n",
    "    \n",
    "    sources = [f\"source_{i}\" for i in range(8)]\n",
    "    results = await asyncio.gather(*[fetch_one(s) for s in sources])\n",
    "    return results\n",
    "\n",
    "def heavy_computation(params):\n",
    "    \"\"\"CPU-bound: Heavy computation on fetched data.\"\"\"\n",
    "    k = params[\"k\"]\n",
    "    # Simulate heavy computation\n",
    "    result = 0\n",
    "    for i in range(100000):\n",
    "        result += np.sin(k * i) ** 2\n",
    "    return {\"source\": params[\"source\"], \"k\": k, \"result\": result}\n",
    "\n",
    "# Step 1: Fetch data concurrently (async)\n",
    "print(\"Step 1: Fetching parameters asynchronously...\")\n",
    "start = time.perf_counter()\n",
    "parameters = await fetch_parameters()\n",
    "fetch_time = time.perf_counter() - start\n",
    "print(f\"  Fetched {len(parameters)} parameter sets in {fetch_time:.2f}s\")\n",
    "\n",
    "# Step 2: Process in parallel (joblib)\n",
    "print(\"\\nStep 2: Processing in parallel...\")\n",
    "start = time.perf_counter()\n",
    "results = Parallel(n_jobs=-1)(delayed(heavy_computation)(p) for p in parameters)\n",
    "compute_time = time.perf_counter() - start\n",
    "print(f\"  Processed {len(results)} results in {compute_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nTotal time: {fetch_time + compute_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3b4",
   "metadata": {},
   "source": [
    "## Common Pitfalls and Best Practices\n",
    "\n",
    "### Pitfall 1: Blocking the Event Loop\n",
    "\n",
    "Never use blocking calls in async code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD: This blocks the entire event loop!\n",
    "async def bad_example():\n",
    "    time.sleep(1)  # WRONG! Blocks everything\n",
    "    return \"done\"\n",
    "\n",
    "# GOOD: Use async sleep\n",
    "async def good_example():\n",
    "    await asyncio.sleep(1)  # Correct! Other tasks can run\n",
    "    return \"done\"\n",
    "\n",
    "# For blocking I/O you can't avoid:\n",
    "async def blocking_io_example():\n",
    "    # Wrap blocking call in executor\n",
    "    result = await asyncio.to_thread(time.sleep, 1)\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5d6",
   "metadata": {},
   "source": [
    "### Pitfall 2: Forgetting to await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def my_coroutine():\n",
    "    return 42\n",
    "\n",
    "# BAD: Forgetting await - you get a coroutine object, not the result\n",
    "result_bad = my_coroutine()  # This is a coroutine, not 42!\n",
    "print(f\"Without await: {result_bad}\")\n",
    "\n",
    "# GOOD: Use await to get the actual result\n",
    "result_good = await my_coroutine()\n",
    "print(f\"With await: {result_good}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7f8",
   "metadata": {},
   "source": [
    "### Pitfall 3: Not Handling Exceptions in gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def might_fail(x):\n",
    "    if x == 3:\n",
    "        raise ValueError(f\"Don't like {x}!\")\n",
    "    await asyncio.sleep(0.1)\n",
    "    return x * 2\n",
    "\n",
    "# By default, gather() raises on first exception\n",
    "try:\n",
    "    results = await asyncio.gather(*[might_fail(i) for i in range(5)])\n",
    "except ValueError as e:\n",
    "    print(f\"Caught error: {e}\")\n",
    "\n",
    "# Better: Use return_exceptions=True to get all results\n",
    "results = await asyncio.gather(\n",
    "    *[might_fail(i) for i in range(5)], \n",
    "    return_exceptions=True\n",
    ")\n",
    "\n",
    "print(\"\\nResults with return_exceptions=True:\")\n",
    "for i, r in enumerate(results):\n",
    "    if isinstance(r, Exception):\n",
    "        print(f\"  Task {i}: ERROR - {r}\")\n",
    "    else:\n",
    "        print(f\"  Task {i}: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9b0",
   "metadata": {},
   "source": [
    "### Best Practices Summary\n",
    "\n",
    "1. **Never block the event loop**: Use `await asyncio.sleep()` not `time.sleep()`. Use `asyncio.to_thread()` for unavoidable blocking calls.\n",
    "\n",
    "2. **Always await coroutines**: Forgetting `await` is a common bug.\n",
    "\n",
    "3. **Use `return_exceptions=True`** in `gather()` when you want all results even if some fail.\n",
    "\n",
    "4. **Rate limit external APIs**: Use semaphores to avoid overwhelming servers.\n",
    "\n",
    "5. **Use timeouts**: Always set timeouts for external I/O with `asyncio.wait_for()`.\n",
    "\n",
    "6. **Close resources properly**: Use `async with` for connections and sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0c1",
   "metadata": {},
   "source": [
    "## Alternatives to asyncio\n",
    "\n",
    "While `asyncio` is Python's built-in solution, there are alternatives worth knowing:\n",
    "\n",
    "### Trio\n",
    "\n",
    "[Trio](https://trio.readthedocs.io/) is a third-party async library with a focus on usability and correctness. It enforces \"structured concurrency\"—all tasks must complete before their parent scope exits.\n",
    "\n",
    "```python\n",
    "import trio\n",
    "\n",
    "async def fetch_data(url):\n",
    "    # Similar to asyncio but with stricter guarantees\n",
    "    await trio.sleep(1)\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def main():\n",
    "    async with trio.open_nursery() as nursery:\n",
    "        nursery.start_soon(fetch_data, \"url1\")\n",
    "        nursery.start_soon(fetch_data, \"url2\")\n",
    "    # All tasks guaranteed complete here\n",
    "\n",
    "trio.run(main)\n",
    "```\n",
    "\n",
    "**When to consider Trio**: If you find asyncio's task management confusing or want stricter guarantees about task completion.\n",
    "\n",
    "### AnyIO\n",
    "\n",
    "[AnyIO](https://anyio.readthedocs.io/) provides a unified API that works with both asyncio and Trio. Write once, run on either.\n",
    "\n",
    "```python\n",
    "import anyio\n",
    "\n",
    "async def main():\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(some_task)\n",
    "        tg.start_soon(another_task)\n",
    "\n",
    "# Run with asyncio backend\n",
    "anyio.run(main, backend='asyncio')\n",
    "\n",
    "# Or run with trio backend\n",
    "anyio.run(main, backend='trio')\n",
    "```\n",
    "\n",
    "**When to consider AnyIO**: If you're writing a library that should work with both asyncio and Trio users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1d2",
   "metadata": {},
   "source": [
    "## When to Use What: Decision Guide\n",
    "\n",
    "Here's how async programming fits with the parallel processing techniques from the [previous chapter](24-parallel-processing.ipynb):\n",
    "\n",
    "| Task Type | Recommended Approach |\n",
    "|-----------|---------------------|\n",
    "| Many HTTP requests | `asyncio` + `aiohttp` |\n",
    "| Polling multiple sensors | `asyncio` |\n",
    "| CPU-heavy computations | `multiprocessing` / `joblib` |\n",
    "| Mix of I/O and CPU | `asyncio` for I/O, then `joblib` for CPU |\n",
    "| Simple file reads | Regular sync code (fast enough) |\n",
    "| Many file reads | `asyncio` + `aiofiles` |\n",
    "| Real-time data streams | `asyncio` with async iterators |\n",
    "| Web server | `asyncio` + `aiohttp` or FastAPI |\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "- **Waiting for responses?** → Async\n",
    "- **Crunching numbers?** → Parallel\n",
    "- **Both?** → Async for I/O, then parallel for compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2e3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This chapter covered asynchronous programming in Python:\n",
    "\n",
    "1. **The Event Loop Model**: One thread efficiently handling many I/O-bound tasks by switching between them during wait times.\n",
    "\n",
    "2. **Core Patterns**:\n",
    "   - `async def` / `await` for defining and calling coroutines\n",
    "   - `asyncio.gather()` for running multiple coroutines concurrently\n",
    "   - `asyncio.create_task()` for background tasks\n",
    "   - `asyncio.as_completed()` for processing results as they arrive\n",
    "   - `asyncio.wait_for()` for timeouts\n",
    "   - Semaphores for rate limiting\n",
    "\n",
    "3. **Async Context Managers and Iterators**: Using `async with` and `async for` for resource management and streaming data.\n",
    "\n",
    "4. **External Libraries**: `aiohttp` for HTTP, `httpx` for a requests-like API, `aiofiles` for file I/O.\n",
    "\n",
    "5. **Combining with Parallel Processing**: Use `asyncio.to_thread()` for blocking code, or combine async I/O with `joblib` for CPU-bound work.\n",
    "\n",
    "6. **Best Practices**: Don't block the event loop, always await coroutines, handle exceptions properly, use timeouts.\n",
    "\n",
    "**Key Takeaway**: Async is about *concurrency* (doing many things by interleaving), while parallel processing (previous chapter) is about *parallelism* (doing many things simultaneously on different cores). Use async when you're I/O-bound, parallel when you're CPU-bound, and combine them when you need both."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
