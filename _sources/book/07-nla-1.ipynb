{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0eadc44",
   "metadata": {},
   "source": [
    "# Nonlinear algebra\n",
    "- KEYWORDS: scipy.optimize.fsolve, scipy.misc.derivative, list comprehension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba50635",
   "metadata": {},
   "source": [
    "## Introduction to nonlinear algebra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aa223",
   "metadata": {},
   "source": [
    "In non-linear algebra, we seek solutions to the equation $f(x) = 0$ where $f(x)$ is *non-linear* in $x$. These are examples of non-linear algebraic equations:\n",
    "\n",
    "-   $e^x=4$\n",
    "-   $x^2 + x - 1 = 0$\n",
    "-   $f(F_A) = F_{A0} - F_{A} - k F_A^2 / \\nu / V = 0$\n",
    "\n",
    "There is not a general theory for whether there is a solution, multiple solutions, or no solution to nonlinear algebraic equations. For example,\n",
    "\n",
    "$sin(x) = 2$ has no solution. We define $f(x) = sin(x) - 2$ and plot it. You can see there no intersections with the x-axis at y=0, meaning no solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f050e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(0, 10)\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x) - 2\n",
    "\n",
    "plt.plot(x, f(x), 'k.-')\n",
    "plt.axhline(0, ls='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32adb59a",
   "metadata": {},
   "source": [
    "In contrast, $sin(x) = 0.5$ will have an infinite number of solutions, everywhere the function intersects the x-axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return np.sin(x) - (x - 4)\n",
    "\n",
    "#plt.plot(x, f2(x))\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.plot(x, 0.025 * (x - 2 * np.pi))\n",
    "#plt.axhline(0, ls='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26961d7",
   "metadata": {},
   "source": [
    "Finally, $sin(x) = x - 1$ has only one solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return np.sin(x) - (x - 1)\n",
    "\n",
    "plt.plot(x, f3(x))\n",
    "plt.axhline(0, ls='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f7553",
   "metadata": {},
   "source": [
    "The equation $e^{-0.5 x} \\sin(x) = 0.5$, evidently has two solutions, but other versions of this equation might have 0, 1, multiple or infinite solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return np.exp(-x) * np.sin(x) + 4000\n",
    "\n",
    "x = np.linspace(-10, 6, 10000)\n",
    "plt.plot(x, f3(x))\n",
    "plt.axhline(0, ls='--')\n",
    "#plt.title('$e^{-0.5 x} \\sin(x) = 0.5$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('objective')\n",
    "plt.ylim([-5, 50]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff62b5",
   "metadata": {},
   "source": [
    "**exercise** modify the equation to see 0, 1, many or infinite solutions.\n",
    "\n",
    "Graphical methods like this are invaluable to visually assess if there are any solutions, and if so how many solutions at least over some range of solutions. Sometimes, this is the fastest way to estimate a solution. Here we focus on nonlinear algebra problems that cannot be analytically solved. These kinds of problems require an iterative solution approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edeeb4",
   "metadata": {},
   "source": [
    "### Newton-Raphson method for finding solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25703a06",
   "metadata": {},
   "source": [
    "Notes adapted from [https://en.wikipedia.org/wiki/Newton%27s_method](https://en.wikipedia.org/wiki/Newton%27s_method).\n",
    "\n",
    "The key idea is that we start with a guess that is close to the solution, and then the function is approximated by a line tangent to the function to find where the line intersects the x-axis. For well-behaved functions, this is a better estimate of where the function equals zero than the first guess. Then, we repeat this until we get sufficiently close to zero.\n",
    "\n",
    "So, we start with the point (x0, f(x0)), and we compute f'(x0), which is the slope of the line tangent to f(x0). We can express an equation for this line as: $y - f(x0) = f'(x0)(x - x0)$ If we now solve this for the $x$ where $y=0$ leads to:\n",
    "\n",
    "$0 = f'(x0)(x - x0) + f(x0)$\n",
    "\n",
    "which leads to\n",
    "\n",
    "$x = x0 - f(x0) / f'(x0)$\n",
    "\n",
    "To implement this, we need to decide what is the tolerance for defining 0, and what is the maximum number of iterations we want to consider?\n",
    "\n",
    "We will first consider what is the square root of 612? This is equivalent to finding a solution to $x^2 = 612$\n",
    "\n",
    "$f(x) = x^2 - 612$\n",
    "\n",
    "Let's start with a guess of x=25, since we know $x^2=625$. We also know $f'(x) = 2x$.\n",
    "\n",
    "The approach is iterative, so we will specify the maximum number of steps to iterate to, and a criteria for stopping.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425cfd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 25\n",
    "\n",
    "def f(x):\n",
    "    return x**2 - 612\n",
    "\n",
    "def fprime(x):\n",
    "    return 2 * x\n",
    "\n",
    "x = x0 - f(x0) / fprime(x0)\n",
    "x, f(x), x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x - f(x) / fprime(x)\n",
    "x, f(x), x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99032745",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = -0.25\n",
    "\n",
    "Nmax = 25  # stop if we hit this many iterations\n",
    "TOL = 1e-6 # stop if we are less than this number\n",
    "\n",
    "def f(x):\n",
    "    \"The function to solve.\"\n",
    "    return x**2 - 612\n",
    "\n",
    "def fprime(x):\n",
    "    \"Derivative of the function to solve.\"\n",
    "    return 2 * x\n",
    "\n",
    "# Here is the iterative solution\n",
    "for i in range(Nmax):\n",
    "    xnew = x0 - f(x0) / fprime(x0)\n",
    "    x0 = xnew\n",
    "\n",
    "    print(f'{i}: {xnew}')\n",
    "    if np.abs(f(xnew)) < TOL:\n",
    "        break\n",
    "\n",
    "    if i == Nmax - 1:\n",
    "        print('Max iterations exceeded')\n",
    "        break\n",
    "\n",
    "print(xnew, xnew**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197da4f2",
   "metadata": {},
   "source": [
    "That is pretty remarkable, it only took two iterations. That is partly because we started pretty close to the answer. Try this again with different initial guesses and see how the number of iterations changes. Also try with negative numbers. There are two solutions that are possible, and the one you get depends on the initial guess.\n",
    "\n",
    "One reason it takes so few iterations here is that Newton's method converges quadratically when you are close to the solution, and in this simple case we have a quadratic function, so we get to the answer in just a few steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10e5da",
   "metadata": {},
   "source": [
    "### Problem problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b036ad",
   "metadata": {},
   "source": [
    "There are pathological situations you can get into. Consider this simple looking polynomial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3 - 2 * x + 2\n",
    "\n",
    "def fprime(x):\n",
    "    return 3 * x**2 - 2\n",
    "\n",
    "x = np.linspace(-2, 2)\n",
    "plt.plot(x, f(x))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a983bed",
   "metadata": {},
   "source": [
    "It seems obvious there is a root near -1.7. But if you use a guess around x=0, the algorithm simply oscillates back and forth and never converges. Let's see:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 2\n",
    "\n",
    "for i in range(Nmax):\n",
    "    xnew = x0 - f(x0) / fprime(x0)\n",
    "    x0 = xnew\n",
    "    print(f'{i}: {xnew}  {f(x0)}  {fprime(x0)}')\n",
    "    if np.abs(f(xnew)) < TOL:\n",
    "        break\n",
    "\n",
    "    if i == Nmax - 1:\n",
    "        print('Max iterations exceeded')\n",
    "        break\n",
    "\n",
    "print(xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14738d62",
   "metadata": {},
   "source": [
    "**Exercise:** Try several initial guesses, and see which ones converge.\n",
    "\n",
    "You can also run into problems when:\n",
    "\n",
    "-   $f'(x) = 0$ at the initial guess, or a subsequent unpdate, then you get a singularity in the update.\n",
    "-   The first derivative is discontinuous at the root. Then you may not converge because the update can bounce back and forth.\n",
    "-   The first derivative is undefined at the root\n",
    "\n",
    "We do not frequently run into these issues, but they do occur from time to time. The solution is usually to use a better initial guess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0eac35",
   "metadata": {},
   "source": [
    "## Derivatives of functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f8531",
   "metadata": {},
   "source": [
    "When you can derive an analytical derivative, you should probably consider doing that, because otherwise we have to approximate the derivatives numerically using finite differences, which is less accurate and computationally more expensive, or we need to use advance libraries that are capable of finding derivatives automatically. We will first see how to the finite differences approach, and later learn about the automatic approach.\n",
    "\n",
    "Let's examine the `scipy.misc.derivative` function. You provide a function, an x-value that you want the derivative at, and a dx to use in a finite-difference formula. By default, three points are used in the difference formula. You want to use a small dx to get an accurate result, but not too small or you can get numerical errors.\n",
    "\n",
    "**exercise**: Try this out with different values of dx from 0.1 to 1e-15.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81f57f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from scipy.misc import derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3\n",
    "\n",
    "x0 = 12\n",
    "\n",
    "derivative(f, x0, dx=1e-6), 3 * x0**2  # the numerical and analytical derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973f5dc",
   "metadata": {},
   "source": [
    "It would be nice to have some adaptive code that just does the right thing to find a dx adaptively. Here is an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5173aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprime(func, x0, dx=0.1, tolerance=1e-6, nmax=10):\n",
    "    \"\"\"Estimate the derivative of func at x0. dx is the initial spacing to use, and\n",
    "    it will be adaptively made smaller to get the derivative accurately with a\n",
    "    tolerance. nmax is the maximum number of divisions to make.\n",
    "\n",
    "    \"\"\"\n",
    "    d0 = derivative(func, x0, dx=dx)\n",
    "    for i in range(nmax):\n",
    "        dx = dx / 2\n",
    "        dnew = derivative(func, x0, dx=dx)\n",
    "        if np.abs(d0 - dnew) <= tolerance:\n",
    "            return dnew\n",
    "        else:\n",
    "            d0 = dnew\n",
    "\n",
    "    # You only get here when the loop has completed and not returned a value\n",
    "    print('Maximum number of divisions reached')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2609b80",
   "metadata": {},
   "source": [
    "And, here is our derivative function in action:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3\n",
    "\n",
    "fprime(f, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2b8ca",
   "metadata": {},
   "source": [
    "Let's wrap the Newton method in a function too, using our fprime function to get the derivative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(func, x0, tolerance=1e-6, nmax=10):\n",
    "    for i in range(nmax):\n",
    "        xnew = x0 - func(x0) / fprime(func, x0)\n",
    "        x0 = xnew\n",
    "        if np.abs(func(xnew)) < tolerance:\n",
    "            return xnew\n",
    "\n",
    "    print('Max iterations exceeded')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06134909",
   "metadata": {},
   "source": [
    "Now, we have a pretty convenient way to solve equations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4646af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 - 612\n",
    "\n",
    "newton(f, 25), np.sqrt(612)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb300b37",
   "metadata": {},
   "source": [
    "This is the basic idea behind nonlinear algebra solvers. Similar to the ode solver we used, there are functions in scipy written to solve nonlinear equations. We consider these next.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85841eb",
   "metadata": {},
   "source": [
    "## fsolve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505b081",
   "metadata": {},
   "source": [
    "`scipy.optimize.fsolve` is the main function we will use to solve nonlinear algebra problems. `fsolve` can be used with functions where you have the derivative, and where you don't.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84240f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ac3f8",
   "metadata": {},
   "source": [
    "Let's see the simplest example.\n",
    "\n",
    "Solve $e^x = 2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(x):\n",
    "    return np.exp(x) - 2  # equal to zero at the solution\n",
    "\n",
    "print(fsolve(objective, 2))\n",
    "print(np.log(2))\n",
    "ans = fsolve(objective, 2)\n",
    "print(f'{float(ans):1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ef14a",
   "metadata": {},
   "source": [
    "Note that the result is an array. We can *unpack* the array with this syntax. Note the comma. Why a comma? it indicates to Python that the results should be unpacked into the variable in a special way, i.e. the first value of the result goes into the first variable. That is all there is in this case.\n",
    "\n",
    "This is the preferred way to get the value of the solution into x:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69315cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = fsolve(objective, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53d10f",
   "metadata": {},
   "source": [
    "Here are two checks on the answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2972cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective(x), x - np.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfe11a",
   "metadata": {},
   "source": [
    "You can get a lot more information by setting full output to 1. Note you have to assign 4 variables to the output in this case. That status will be 1 if it succeeds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans, info, status, msg = fsolve(objective, 2, full_output=1)\n",
    "ans, info, status, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046193be",
   "metadata": {},
   "source": [
    "Here is an example with no solution, and a different status flag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective2(x):\n",
    "    return np.exp(x) + 2\n",
    "\n",
    "results = fsolve(objective2, 2, full_output=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eba12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans, = results[0]\n",
    "objective2(ans), np.abs(objective2(ans)) <= 1e-6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c98fe40",
   "metadata": {},
   "source": [
    "```{note}\n",
    "scipy.optimize.root is preferred now.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94daba",
   "metadata": {},
   "source": [
    "## A worked example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9361e3",
   "metadata": {},
   "source": [
    "We can integrate fsolve with a variety of other problems. For example, here is an integral equation we need to solve in engineering problems. The volume of a plug flow reactor can be defined by this equation: $V = \\int_{Fa(V=0)}^{Fa} \\frac{1}{r_a} dFa$ where $r_a$ is the rate law. Suppose we know the reactor volume is 100 L, the inlet concentration of A is 1 mol/L, the volumetric flow is 10 L/min, and $r_a = -k Ca$, with $k=0.23$ 1/min. What is the exit molar flow rate? We need to solve the following equation:\n",
    "\n",
    "$$100 = \\int_{Fa(V=0)}^{Fa} \\frac{1}{-k Fa/\\nu} dFa$$\n",
    "\n",
    "The equation to solve here is:\n",
    "\n",
    "$f(Fa) = 100 - \\int_{Fa(V=0)}^{Fa} \\frac{1}{-k Fa/\\nu} dFa$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b07a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "k = 0.23   # 1 / min\n",
    "nu = 10.0  # L / min\n",
    "Cao = 1.0  # mol / L\n",
    "Fa0 = Cao * nu\n",
    "\n",
    "def integrand(Fa):\n",
    "    return -1.0 / (k * Fa / nu)\n",
    "\n",
    "def objective(Fa):\n",
    "    integral, err = quad(integrand, Fa0, Fa)\n",
    "    return 100.0 - integral\n",
    "\n",
    "objective(0.15*Fa0), 0.15 * Fa0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675d631",
   "metadata": {},
   "source": [
    "To make a plot, there is a subtlety. We cannot integrate an array of $F_A$ values. Previously, we used a for loop to get around this. There is another syntax called *list comprehension* that we can also use:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59597e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "[objective(fa) for fa in [0.01, 0.1, 1, 2]]  # list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8a735",
   "metadata": {},
   "source": [
    "You can already see the answer must be between 1 and 2 because the sign changes between these two values, and that it is closer to 1 than 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fa = np.linspace(0.01, Fa0)\n",
    "obj = [objective(f) for f in fa]\n",
    "plt.plot(fa, obj)\n",
    "plt.xlabel('Molar flow rate (mol/min)')\n",
    "plt.ylabel('objective')\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(1, color='k', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27816a88",
   "metadata": {},
   "source": [
    "You can see there is one answer in this range, near a flow rate of 1.0 mol/min. We use that as an initial guess for fsolve:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a237c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fa_guess = 1.0\n",
    "Fa_exit, = fsolve(objective, Fa_guess)\n",
    "print(f'The exit flow rate is {Fa_exit:1.4f} mol/min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the answer different ways.\n",
    "objective(Fa_exit), quad(integrand, Fa0, Fa_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ecf38",
   "metadata": {},
   "source": [
    "## Parameterized objective functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d6cbf",
   "metadata": {},
   "source": [
    "Now, suppose we want to see how our solution varies with a parameter value. For example, we can change the rate constant by changing the temperature. Say we want to compute the exit molar flow rate at a range of rate constants, e.g. from 0.02 to 2 1/min. In other words, we treat the rate constant as a *parameter* and use it in an additional argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e62a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(Fa, k):\n",
    "    return -1.0 / (k * Fa / nu)\n",
    "\n",
    "def objective(Fa, k):\n",
    "    integral, err = quad(integrand, Fa0, Fa, args=(k,))\n",
    "    return 100.0 - integral\n",
    "\n",
    "KRANGE = np.linspace(0.02, 2)\n",
    "\n",
    "fa_exit = np.zeros(KRANGE.shape)\n",
    "\n",
    "guess = 1.0\n",
    "\n",
    "for i, k in enumerate(KRANGE):\n",
    "    ans, info, status, msg = fsolve(objective, guess, args=(k,), full_output=1)\n",
    "    if status == 1:\n",
    "        fa_exit[i] = ans\n",
    "        guess = ans\n",
    "    else:\n",
    "        print(f'k = {k} failed. {msg}')\n",
    "\n",
    "X = (Fa0 - fa_exit) / Fa0 \n",
    "plt.plot(KRANGE, X, 'b.-')\n",
    "plt.xlabel('k (1/min)')\n",
    "plt.ylabel('Conversion');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ec6f0",
   "metadata": {},
   "source": [
    "You can see here that any rate constant above about 0.5 1/min leads to near complete conversion, so heating above the temperature required for this would be wasteful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078e367",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3503ed5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In this lecture we reviewed methods to solve non-linear algebraic equations (they also work on linear algebra, but it is considered wasteful since there are more efficient methods to solve those).\n",
    "\n",
    "-   The key idea is to create a function that is equal to zero at the solution, and then use `scipy.optimize.fsolve` with an initial guess to find the solution.\n",
    "-   We introduced *list comprehension* which is a convenient syntax for for loops.\n",
    "-   We also looked at `scipy.misc.derivative` which is a convenient way to numerically estimate the derivative of a function by finite difference formulas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}